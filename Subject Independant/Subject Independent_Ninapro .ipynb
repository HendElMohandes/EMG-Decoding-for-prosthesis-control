{"cells":[{"cell_type":"markdown","metadata":{"id":"FVw_sHiQav9Y"},"source":["### **Connecting with Drive**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4176,"status":"ok","timestamp":1734603495268,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"3fuk29ccavxQ","outputId":"37633628-59d8-4b29-ed51-3f50e74c05bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Reading the training data Subject\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"OWU0BwfKaqMa"},"source":["### **Importing All needed libraries**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1734603495268,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"zvMx9ro8ZntG","outputId":"e792e28b-391a-404a-bcdf-a2d0c0ea2dfd"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n"]}],"source":["#Importing all needed libraries\n","import pandas as pd\n","import numpy as np #Matric math\n","import tensorflow as tf #ML\n","from tensorflow.python.framework import ops\n","from random import randint\n","from numpy import array\n","from numpy import argmax\n","import keras.backend as K\n","from tensorflow.keras import models\n","from numpy import array_equal\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Bidirectional\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import TimeDistributed\n","from tensorflow.keras.layers import RepeatVector\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","from scipy.io import loadmat\n","from scipy.io import loadmat\n","\n","# sys.path.append(os.path.abspath(\"/Users/henda/anaconda3/Lib/site-packages\"))\n","# from rnn_utils import *\n","# from public_tests import *\n","ops.reset_default_graph()\n","\n","tf.compat.v1.reset_default_graph() #Clearning cache\n","sess=tf.compat.v1.InteractiveSession()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f27nYeB4a4F9"},"source":["### **Reading the Training dataset**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rSSsBybQa36e","executionInfo":{"status":"ok","timestamp":1734603495268,"user_tz":-240,"elapsed":8,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"}}},"outputs":[],"source":["import pandas as pd\n","from scipy.io import loadmat\n","\n","def load_files():\n","    full_data = pd.DataFrame()\n","    subjects_to_load = [1,3,5,6,7,8,9,10,11]\n","\n","    for i in subjects_to_load:\n","        # Load the .mat file\n","        training_data = loadmat(f'/content/drive/My Drive/Colab Notebooks/processed withstim/S{i}_E1.mat')\n","        Data = training_data[\"Data\"]\n","        Data_df = pd.DataFrame(Data)\n","        full_data = pd.concat([full_data, Data_df], ignore_index=True)\n","    return full_data\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1734603495268,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"3BAxdx-QcIwn","outputId":"1932f235-6359-475e-cc40-b0576bf29b6c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             0         1         2         3         4         5         6   \\\n","0      0.652864  0.530705  0.739539  0.701483  0.528111  0.805447  0.683260   \n","1      0.648498  0.530705  0.738417  0.696472  0.529103  0.806432  0.683260   \n","2      0.648426  0.519349  0.737575  0.701723  0.523797  0.805182  0.681295   \n","3      0.646388  0.530480  0.739259  0.699609  0.531441  0.807466  0.685004   \n","4      0.650530  0.533190  0.739257  0.699825  0.533375  0.808103  0.688155   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","82022  0.579613  0.634946  0.562432  0.737734  0.651783  0.605426  0.716873   \n","82023  0.608090  0.609223  0.589140  0.723470  0.614642  0.651421  0.697862   \n","82024  0.597995  0.597469  0.615590  0.707872  0.580551  0.695557  0.693106   \n","82025  0.591268  0.574709  0.618580  0.696352  0.556119  0.704743  0.672717   \n","82026  0.596114  0.589266  0.630896  0.695959  0.552410  0.714224  0.683153   \n","\n","             7         8         9   ...        73        74        75  \\\n","0      0.356153  0.694081  0.710107  ...  0.002965  0.026713  0.009411   \n","1      0.355579  0.691954  0.717659  ...  0.003313  0.017410  0.012861   \n","2      0.351392  0.688143  0.712003  ...  0.002541  0.012399  0.014314   \n","3      0.355577  0.689305  0.715768  ...  0.002981  0.014918  0.009515   \n","4      0.355579  0.704201  0.717659  ...  0.003400  0.021507  0.011873   \n","...         ...       ...       ...  ...       ...       ...       ...   \n","82022  0.559049  0.854303  0.748481  ...  0.031994  0.043463  0.093284   \n","82023  0.538956  0.838900  0.728230  ...  0.030574  0.033406  0.082356   \n","82024  0.509153  0.813056  0.736915  ...  0.042141  0.041796  0.069273   \n","82025  0.497353  0.799376  0.706318  ...  0.037183  0.057157  0.129710   \n","82026  0.489838  0.791571  0.713866  ...  0.040653  0.037537  0.080965   \n","\n","             76        77        78        79        80        81    82  \n","0      0.002163  0.009314  0.003002  0.004143  0.045896  0.174906   0.0  \n","1      0.002893  0.011303  0.004596  0.004695  0.043423  0.128346   0.0  \n","2      0.001169  0.006746  0.003317  0.002436  0.050508  0.124272   0.0  \n","3      0.001943  0.010017  0.004264  0.004030  0.035231  0.138247   0.0  \n","4      0.001533  0.008065  0.003501  0.003971  0.051130  0.170656   0.0  \n","...         ...       ...       ...       ...       ...       ...   ...  \n","82022  0.042815  0.054687  0.052606  0.014951  0.161288  0.089513  17.0  \n","82023  0.043418  0.043733  0.062681  0.014997  0.180240  0.072349  17.0  \n","82024  0.046755  0.072634  0.093328  0.025380  0.197048  0.071308  17.0  \n","82025  0.048599  0.127234  0.063206  0.010009  0.115575  0.070569  17.0  \n","82026  0.066768  0.095795  0.107073  0.016503  0.182609  0.082998   0.0  \n","\n","[82027 rows x 83 columns]"],"text/html":["\n","  <div id=\"df-e217adb0-cca2-4af7-b400-281ac9a91832\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>73</th>\n","      <th>74</th>\n","      <th>75</th>\n","      <th>76</th>\n","      <th>77</th>\n","      <th>78</th>\n","      <th>79</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.652864</td>\n","      <td>0.530705</td>\n","      <td>0.739539</td>\n","      <td>0.701483</td>\n","      <td>0.528111</td>\n","      <td>0.805447</td>\n","      <td>0.683260</td>\n","      <td>0.356153</td>\n","      <td>0.694081</td>\n","      <td>0.710107</td>\n","      <td>...</td>\n","      <td>0.002965</td>\n","      <td>0.026713</td>\n","      <td>0.009411</td>\n","      <td>0.002163</td>\n","      <td>0.009314</td>\n","      <td>0.003002</td>\n","      <td>0.004143</td>\n","      <td>0.045896</td>\n","      <td>0.174906</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.648498</td>\n","      <td>0.530705</td>\n","      <td>0.738417</td>\n","      <td>0.696472</td>\n","      <td>0.529103</td>\n","      <td>0.806432</td>\n","      <td>0.683260</td>\n","      <td>0.355579</td>\n","      <td>0.691954</td>\n","      <td>0.717659</td>\n","      <td>...</td>\n","      <td>0.003313</td>\n","      <td>0.017410</td>\n","      <td>0.012861</td>\n","      <td>0.002893</td>\n","      <td>0.011303</td>\n","      <td>0.004596</td>\n","      <td>0.004695</td>\n","      <td>0.043423</td>\n","      <td>0.128346</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.648426</td>\n","      <td>0.519349</td>\n","      <td>0.737575</td>\n","      <td>0.701723</td>\n","      <td>0.523797</td>\n","      <td>0.805182</td>\n","      <td>0.681295</td>\n","      <td>0.351392</td>\n","      <td>0.688143</td>\n","      <td>0.712003</td>\n","      <td>...</td>\n","      <td>0.002541</td>\n","      <td>0.012399</td>\n","      <td>0.014314</td>\n","      <td>0.001169</td>\n","      <td>0.006746</td>\n","      <td>0.003317</td>\n","      <td>0.002436</td>\n","      <td>0.050508</td>\n","      <td>0.124272</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.646388</td>\n","      <td>0.530480</td>\n","      <td>0.739259</td>\n","      <td>0.699609</td>\n","      <td>0.531441</td>\n","      <td>0.807466</td>\n","      <td>0.685004</td>\n","      <td>0.355577</td>\n","      <td>0.689305</td>\n","      <td>0.715768</td>\n","      <td>...</td>\n","      <td>0.002981</td>\n","      <td>0.014918</td>\n","      <td>0.009515</td>\n","      <td>0.001943</td>\n","      <td>0.010017</td>\n","      <td>0.004264</td>\n","      <td>0.004030</td>\n","      <td>0.035231</td>\n","      <td>0.138247</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.650530</td>\n","      <td>0.533190</td>\n","      <td>0.739257</td>\n","      <td>0.699825</td>\n","      <td>0.533375</td>\n","      <td>0.808103</td>\n","      <td>0.688155</td>\n","      <td>0.355579</td>\n","      <td>0.704201</td>\n","      <td>0.717659</td>\n","      <td>...</td>\n","      <td>0.003400</td>\n","      <td>0.021507</td>\n","      <td>0.011873</td>\n","      <td>0.001533</td>\n","      <td>0.008065</td>\n","      <td>0.003501</td>\n","      <td>0.003971</td>\n","      <td>0.051130</td>\n","      <td>0.170656</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>82022</th>\n","      <td>0.579613</td>\n","      <td>0.634946</td>\n","      <td>0.562432</td>\n","      <td>0.737734</td>\n","      <td>0.651783</td>\n","      <td>0.605426</td>\n","      <td>0.716873</td>\n","      <td>0.559049</td>\n","      <td>0.854303</td>\n","      <td>0.748481</td>\n","      <td>...</td>\n","      <td>0.031994</td>\n","      <td>0.043463</td>\n","      <td>0.093284</td>\n","      <td>0.042815</td>\n","      <td>0.054687</td>\n","      <td>0.052606</td>\n","      <td>0.014951</td>\n","      <td>0.161288</td>\n","      <td>0.089513</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>82023</th>\n","      <td>0.608090</td>\n","      <td>0.609223</td>\n","      <td>0.589140</td>\n","      <td>0.723470</td>\n","      <td>0.614642</td>\n","      <td>0.651421</td>\n","      <td>0.697862</td>\n","      <td>0.538956</td>\n","      <td>0.838900</td>\n","      <td>0.728230</td>\n","      <td>...</td>\n","      <td>0.030574</td>\n","      <td>0.033406</td>\n","      <td>0.082356</td>\n","      <td>0.043418</td>\n","      <td>0.043733</td>\n","      <td>0.062681</td>\n","      <td>0.014997</td>\n","      <td>0.180240</td>\n","      <td>0.072349</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>82024</th>\n","      <td>0.597995</td>\n","      <td>0.597469</td>\n","      <td>0.615590</td>\n","      <td>0.707872</td>\n","      <td>0.580551</td>\n","      <td>0.695557</td>\n","      <td>0.693106</td>\n","      <td>0.509153</td>\n","      <td>0.813056</td>\n","      <td>0.736915</td>\n","      <td>...</td>\n","      <td>0.042141</td>\n","      <td>0.041796</td>\n","      <td>0.069273</td>\n","      <td>0.046755</td>\n","      <td>0.072634</td>\n","      <td>0.093328</td>\n","      <td>0.025380</td>\n","      <td>0.197048</td>\n","      <td>0.071308</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>82025</th>\n","      <td>0.591268</td>\n","      <td>0.574709</td>\n","      <td>0.618580</td>\n","      <td>0.696352</td>\n","      <td>0.556119</td>\n","      <td>0.704743</td>\n","      <td>0.672717</td>\n","      <td>0.497353</td>\n","      <td>0.799376</td>\n","      <td>0.706318</td>\n","      <td>...</td>\n","      <td>0.037183</td>\n","      <td>0.057157</td>\n","      <td>0.129710</td>\n","      <td>0.048599</td>\n","      <td>0.127234</td>\n","      <td>0.063206</td>\n","      <td>0.010009</td>\n","      <td>0.115575</td>\n","      <td>0.070569</td>\n","      <td>17.0</td>\n","    </tr>\n","    <tr>\n","      <th>82026</th>\n","      <td>0.596114</td>\n","      <td>0.589266</td>\n","      <td>0.630896</td>\n","      <td>0.695959</td>\n","      <td>0.552410</td>\n","      <td>0.714224</td>\n","      <td>0.683153</td>\n","      <td>0.489838</td>\n","      <td>0.791571</td>\n","      <td>0.713866</td>\n","      <td>...</td>\n","      <td>0.040653</td>\n","      <td>0.037537</td>\n","      <td>0.080965</td>\n","      <td>0.066768</td>\n","      <td>0.095795</td>\n","      <td>0.107073</td>\n","      <td>0.016503</td>\n","      <td>0.182609</td>\n","      <td>0.082998</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>82027 rows × 83 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e217adb0-cca2-4af7-b400-281ac9a91832')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e217adb0-cca2-4af7-b400-281ac9a91832 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e217adb0-cca2-4af7-b400-281ac9a91832');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-18dd945c-eca0-4320-a98a-30f81c50ea15\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18dd945c-eca0-4320-a98a-30f81c50ea15')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-18dd945c-eca0-4320-a98a-30f81c50ea15 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_3429b2fe-c6cf-4854-9824-ab0997f51c23\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Data1')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3429b2fe-c6cf-4854-9824-ab0997f51c23 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('Data1');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"Data1"}},"metadata":{},"execution_count":9}],"source":["Data1 = load_files()\n","Data1"]},{"cell_type":"markdown","metadata":{"id":"3O4YAmlwccNi"},"source":["### **Preparing the training dataset**"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":945,"status":"ok","timestamp":1734603496208,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"YmPV-5jvccB0","outputId":"cdd254b7-f795-49da-ee39-cc4d7d38a893"},"outputs":[{"output_type":"stream","name":"stdout","text":["(82027, 22)\n","(82027, 24)\n"]}],"source":["Data1=np.array(Data1)\n","\n","# Extract features and targets for training\n","X_train = Data1[:, 36:58]   # Target for training\n","Z_train = Data1[:, 58:82]  # Input features for training\n","\n","\n","del Data1\n","#####################################################\n","print(X_train.shape)\n","print(Z_train.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"Xko9re4oc81e"},"source":["### **Reading Test datase**"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1444,"status":"ok","timestamp":1734603497651,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"zk-Pkrfmc8rn","outputId":"d3608578-d462-4f3e-9681-fd40fd4e4a8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(9108, 83)\n"]}],"source":["data_path = '/content/drive/My Drive/Colab Notebooks/processed withstim/S4_E1.mat'\n","\n","\n","test_data = loadmat(data_path)\n","Data=test_data[\"Data\"]\n","Data1=np.array(Data)\n","\n","print(Data1.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1734603497651,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"gIHovXLTekx-","outputId":"75ed4c3d-a82b-4cf6-ed3e-69b0ce02f674"},"outputs":[{"output_type":"stream","name":"stdout","text":["(9108, 22)\n","(9108, 24)\n"]}],"source":["X_test = Data1[:, 36:58]  # Target for testing it starts at 36 and ends at 58\n","Z_test = Data1[:, 58:82]  # Input features for testing\n","del Data1\n","print(X_test.shape)\n","print(Z_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"TpUgnKUbfcN3"},"source":["### **Reshaping of training and testing datase**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1734603497651,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"pt3qXJx9fb-G","outputId":"72505511-b573-43df-b7ba-2cc5b76def41"},"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM training input shape: (82013, 15, 24), LSTM training output shape: (82013, 22)\n","LSTM testing input shape: (9094, 15, 24), LSTM testing output shape: (9094, 22)\n"]}],"source":["sequence_length=15\n","n_features=24\n","# Prepare input and output for LSTM (training)\n","n_sequences_train = len(Z_train) - sequence_length + 1\n","in_train = np.zeros((n_sequences_train, sequence_length, n_features))\n","out_train = np.zeros((n_sequences_train, X_train.shape[1]))  # Output shape should match target\n","\n","for j in range(n_sequences_train):\n","  in_train[j] = Z_train[j:j + sequence_length]\n","  out_train[j] = X_train[j + sequence_length - 1]  # Target is the last step in the sequence\n","\n","    # Prepare input and output for LSTM (testing)\n","n_sequences_test = len(Z_test) - sequence_length + 1\n","in_test = np.zeros((n_sequences_test, sequence_length, n_features))\n","out_test = np.zeros((n_sequences_test, X_test.shape[1]))\n","\n","for j in range(n_sequences_test):\n","  in_test[j] = Z_test[j:j + sequence_length]\n","  out_test[j] = X_test[j + sequence_length - 1]  # Target is the last step in the sequence\n","\n","# Print the shape of the prepared data for sanity check\n","print(f\"LSTM training input shape: {in_train.shape}, LSTM training output shape: {out_train.shape}\")\n","print(f\"LSTM testing input shape: {in_test.shape}, LSTM testing output shape: {out_test.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"LHN3FbMa-BJS"},"source":["### **Seperate Validation Dataset**"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1769,"status":"ok","timestamp":1734603499417,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"TEZ9xPgr-A9L","outputId":"92d0a2bf-d951-412f-c07a-64864117b16f"},"outputs":[{"output_type":"stream","name":"stdout","text":["The validation data is from subject :29\n","(8960, 83)\n","(8960, 22)\n","(8960, 24)\n","val input shape: (8946, 15, 24), LSTM val output shape: (8946, 22)\n"]}],"source":["import random\n","\n","# Define the range and the exclusions\n","numbers = list(range(1, 41))\n","exclusions = {28, 2, 3,1}\n","# Remove the excluded numbers\n","valid_numbers = [num for num in numbers if num not in exclusions]\n","# Generate a random number from the valid list\n","i = random.choice(valid_numbers)\n","\n","print(f\"The validation data is from subject :{i}\")\n","\n","data_path = f'/content/drive/My Drive/Colab Notebooks/processed withstim/S{i}_E1.mat'\n","\n","\n","val_data = loadmat(data_path)\n","Data=val_data[\"Data\"]\n","Data1=np.array(Data)\n","\n","print(Data1.shape)\n","X_val = Data1[:, 36:58]   # Target for testing\n","Z_val = Data1[:, 58:82]  # Input features for testing\n","del Data1\n","print(X_val.shape)\n","print(Z_val.shape)\n","\n","#prepare validation datase\n","\n","sequence_length=15\n","n_features=24\n","# Prepare input and output for LSTM (training)\n","n_sequences_val = len(Z_val) - sequence_length + 1\n","in_val = np.zeros((n_sequences_val, sequence_length, n_features))\n","out_val = np.zeros((n_sequences_val, X_val.shape[1]))  # Output shape should match target\n","\n","for j in range(n_sequences_val):\n","  in_train[j] = Z_val[j:j + sequence_length]\n","  out_train[j] = X_val[j + sequence_length - 1]  # Target is the last step in the sequence\n","\n","print(f\"val input shape: {in_val.shape}, LSTM val output shape: {out_val.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"_FOAcRu8eydX"},"source":["### **Create the Model**"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":989},"executionInfo":{"elapsed":1545,"status":"ok","timestamp":1734603500960,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"RLnfXIFIeyIz","outputId":"d703557a-8ff5-48d2-e889-3d8771a76583"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ domain_specific_normaliz… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │             \u001b[38;5;34m48\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","│ (\u001b[38;5;33mDomainSpecificNormaliza…\u001b[0m │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m2,304\u001b[0m │ domain_specific_norma… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ max_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m6,144\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ max_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ simple_gnn_layer          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,096\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","│ (\u001b[38;5;33mSimpleGNNLayer\u001b[0m)          │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bidirectional             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │      \u001b[38;5;34m2,260,000\u001b[0m │ simple_gnn_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │      \u001b[38;5;34m1,025,768\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n","│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n","│                           │                        │                │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │          \u001b[38;5;34m2,000\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n","│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │        \u001b[38;5;34m400,400\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │         \u001b[38;5;34m80,200\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ global_average_pooling1d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n","│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)             │          \u001b[38;5;34m4,422\u001b[0m │ global_average_poolin… │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ domain_specific_normaliz… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DomainSpecificNormaliza…</span> │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │ domain_specific_norma… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ max_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ max_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ simple_gnn_layer          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleGNNLayer</span>)          │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ bidirectional             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,260,000</span> │ simple_gnn_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025,768</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n","│                           │                        │                │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">400,400</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,200</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ global_average_pooling1d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,422</span> │ global_average_poolin… │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,785,766\u001b[0m (14.44 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,785,766</span> (14.44 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,785,574\u001b[0m (14.44 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,785,574</span> (14.44 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["from tensorflow import keras\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector\n","from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, MaxPooling1D, Dense, Dropout, LSTM, Bidirectional\n","from tensorflow.keras.layers import Attention\n","from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Add\n","from tensorflow.keras import activations, Input\n","from tensorflow.keras.models import Model\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","\n","\n","# Define our settings\n","numResponses = 22\n","numHiddenUnits = 500\n","timesteps = 15  # Number of timesteps (sequence length)\n","input_features = 24\n","\n","class SimpleGNNLayer(tf.keras.layers.Layer):\n","    def __init__(self, num_features, **kwargs):\n","        super(SimpleGNNLayer, self).__init__(**kwargs)\n","        self.num_features = num_features\n","\n","    def build(self, input_shape):\n","        # Adjacency matrix for feature-to-feature relationships\n","        self.adjacency_matrix = self.add_weight(\n","            shape=(input_shape[-1], self.num_features),  # input_features -> num_features\n","            initializer=\"random_normal\",\n","            trainable=True,\n","            name=\"adjacency_matrix\"\n","        )\n","\n","    def call(self, inputs):\n","        # Compute new features via adjacency matrix multiplication\n","        # This keeps (batch_size, timesteps, num_features) intact\n","        return tf.einsum('bti,ij->btj', inputs, self.adjacency_matrix)  # Batch matmul\n","\n","\n","# Custom Domain-Specific Normalization Layer\n","class DomainSpecificNormalization(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super(DomainSpecificNormalization, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.gamma = self.add_weight(\n","            shape=(1, 1, input_shape[-1]),\n","            initializer=\"ones\",\n","            trainable=True,\n","            name=\"gamma\"\n","        )\n","        self.beta = self.add_weight(\n","            shape=(1, 1, input_shape[-1]),\n","            initializer=\"zeros\",\n","            trainable=True,\n","            name=\"beta\"\n","        )\n","\n","    def call(self, inputs):\n","        mean = tf.reduce_mean(inputs, axis=(1, 2), keepdims=True)\n","        std = tf.math.reduce_std(inputs, axis=(1, 2), keepdims=True)\n","        normalized = (inputs - mean) / (std + tf.keras.backend.epsilon())\n","        return self.gamma * normalized + self.beta\n","\n","\n","inputs = Input(shape=(timesteps, input_features))\n","\n","# Domain-Specific Normalization\n","x = DomainSpecificNormalization()(inputs)\n","\n","# Convolutional layers\n","x = Conv1D(32, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling1D(pool_size=2, strides=1, padding='same')(x)\n","\n","x = Conv1D(64, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = MaxPooling1D(pool_size=2, strides=1, padding='same')(x)\n","\n","# GNN Layer (Preserves timesteps)\n","x = SimpleGNNLayer(num_features=64)(x)\n","\n","# Bidirectional LSTM layers\n","x = Bidirectional(LSTM(500, return_sequences=True))(x)\n","x = Dropout(0.2)(x)\n","\n","# Multi-Head Attention\n","attn_output = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n","x = Add()([x, attn_output])  # Residual connection\n","x = LayerNormalization()(x)\n","\n","# Dense Layers and Output\n","x = Dense(400, activation='relu')(x)\n","x = Dense(200, activation='relu')(x)\n","\n","# Flatten sequence dimension before final output\n","x = tf.keras.layers.GlobalAveragePooling1D()(x)\n","\n","# Final output for DOFs\n","outputs = Dense(numResponses, activation='linear')(x)\n","\n","# Define model\n","model = Model(inputs, outputs)\n","model.summary()\n","\n","\n","\n","# ########      LSTM- CNN Hybrid        ##########\n","\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, MaxPooling1D, Dense, Dropout, Bidirectional, LSTM\n","# from tensorflow.keras import activations\n","\n","# # Define optimized CNN-LSTM architecture\n","# model = Sequential()\n","\n","# # 1st convolutional layer\n","# model.add(Conv1D(32, kernel_size=3, strides=1, padding='same', use_bias=False, input_shape=(timesteps, input_features)))  # 15 timesteps, 24 features\n","# model.add(BatchNormalization())\n","# model.add(Activation(activations.relu))\n","# model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n","\n","# # 2nd convolutional layer\n","# model.add(Conv1D(64, kernel_size=3, strides=1, padding='same', use_bias=False))\n","# model.add(BatchNormalization())\n","# model.add(Activation(activations.relu))\n","# model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n","\n","# # 3rd convolutional layer\n","# model.add(Conv1D(128, kernel_size=3, strides=1, padding='same', use_bias=False))\n","# model.add(BatchNormalization())\n","# model.add(Activation(activations.relu))\n","# model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n","\n","\n","# # Dense layer before LSTM\n","# model.add(Dense(400, activation='relu'))\n","\n","# # Bidirectional LSTM layers\n","# model.add(Bidirectional(LSTM(1000, return_sequences=True)))\n","# model.add(Dropout(0.2))\n","\n","# model.add(Bidirectional(LSTM(1000)))\n","# model.add(Dropout(0.2))\n","# # Final output layer for predicting 22 degrees of freedom (DOFs)\n","# model.add(Dense(numResponses, activation='relu'))  # Adjust the number of outputs for your case (22 DOFs)\n","\n","# # Print model summary\n","# model.summary()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mEIUVBxYhYhS"},"source":["### **Train the model**"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDqKSALrhYUu","executionInfo":{"status":"ok","timestamp":1734604911217,"user_tz":-240,"elapsed":1410260,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"}},"outputId":"4e18b54d-4378-454f-c752-944f22418d8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - loss: 0.0261 - val_loss: 0.3762 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0098 - val_loss: 0.3854 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0074 - val_loss: 0.2820 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0060 - val_loss: 0.2702 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.2611 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.2727 - learning_rate: 0.0010\n","Epoch 7/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.2835 - learning_rate: 0.0010\n","Epoch 8/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0034 - val_loss: 0.2810 - learning_rate: 0.0010\n","Epoch 9/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.2603 - learning_rate: 0.0010\n","Epoch 10/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0029 - val_loss: 0.2748 - learning_rate: 0.0010\n","Epoch 11/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.2750 - learning_rate: 0.0010\n","Epoch 12/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.2609 - learning_rate: 0.0010\n","Epoch 13/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.2569 - learning_rate: 0.0010\n","Epoch 14/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.3259 - learning_rate: 0.0010\n","Epoch 15/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0021 - val_loss: 0.3069 - learning_rate: 0.0010\n","Epoch 16/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.3042 - learning_rate: 0.0010\n","Epoch 17/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.2966 - learning_rate: 0.0010\n","Epoch 18/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.3043 - learning_rate: 0.0010\n","Epoch 19/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 0.2701 - learning_rate: 0.0010\n","Epoch 20/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.3046 - learning_rate: 0.0010\n","Epoch 21/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.2888 - learning_rate: 0.0010\n","Epoch 22/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.2937 - learning_rate: 0.0010\n","Epoch 23/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.3001 - learning_rate: 0.0010\n","Epoch 24/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.3235 - learning_rate: 0.0010\n","Epoch 25/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.3236 - learning_rate: 0.0010\n","Epoch 26/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.3080 - learning_rate: 0.0010\n","Epoch 27/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.3140 - learning_rate: 0.0010\n","Epoch 28/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.3179 - learning_rate: 0.0010\n","Epoch 29/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.3134 - learning_rate: 5.0000e-04\n","Epoch 30/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.3158 - learning_rate: 5.0000e-04\n","Epoch 31/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.3275 - learning_rate: 5.0000e-04\n","Epoch 32/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 9.8096e-04 - val_loss: 0.3300 - learning_rate: 5.0000e-04\n","Epoch 33/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 9.6425e-04 - val_loss: 0.3066 - learning_rate: 5.0000e-04\n","Epoch 34/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 9.4006e-04 - val_loss: 0.3305 - learning_rate: 5.0000e-04\n","Epoch 35/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 9.2406e-04 - val_loss: 0.3293 - learning_rate: 5.0000e-04\n","Epoch 36/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 9.0293e-04 - val_loss: 0.3230 - learning_rate: 5.0000e-04\n","Epoch 37/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 8.9520e-04 - val_loss: 0.3123 - learning_rate: 5.0000e-04\n","Epoch 38/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 8.7216e-04 - val_loss: 0.3024 - learning_rate: 5.0000e-04\n","Epoch 39/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 8.6419e-04 - val_loss: 0.3202 - learning_rate: 5.0000e-04\n","Epoch 40/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 8.4423e-04 - val_loss: 0.3196 - learning_rate: 5.0000e-04\n","Epoch 41/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 8.3435e-04 - val_loss: 0.3303 - learning_rate: 5.0000e-04\n","Epoch 42/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 8.1450e-04 - val_loss: 0.3232 - learning_rate: 5.0000e-04\n","Epoch 43/200\n","\u001b[1m2563/2563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - loss: 8.3070e-04 - val_loss: 0.3134 - learning_rate: 5.0000e-04\n"]}],"source":["import numpy as np\n","import math\n","from sklearn.metrics import mean_squared_error\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","\n","######### Model Training ##########\n","# Compile the model with Adam optimizer and Mean Squared Error loss\n","optimizer = Adam(learning_rate=0.001)  # Initial learning rate\n","model.compile(optimizer=optimizer, loss='mean_squared_error')\n","\n","# ReduceLROnPlateau callback to dynamically reduce the learning rate if the model stops improving\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6)\n","\n","# Early stopping to prevent overfitting\n","early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n","\n","# Train the model\n","# history = model.fit(in_train, out_train, validation_split=0.2, batch_size=32, epochs=200, verbose=1, callbacks=[early_stopping, reduce_lr])\n","history = model.fit(in_train, out_train, validation_data=(in_val,out_val), batch_size=32, epochs=200, verbose=1, callbacks=[early_stopping, reduce_lr])\n"]},{"cell_type":"markdown","metadata":{"id":"RyjMiUsUhxpO"},"source":["### **Test the Model**"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r5MjEZnLhxb4","executionInfo":{"status":"ok","timestamp":1734604913495,"user_tz":-240,"elapsed":2323,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"}},"outputId":"5d93d562-db2f-4c57-a05e-facb5aa8877a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n","Predicted output shape: (9094, 22)\n","Actual test output shape: (9094, 22)\n","Pearson correlation for DOF 1: 0.33\n","RMSE for DOF 1: 0.18\n","Pearson correlation for DOF 2: 0.04\n","RMSE for DOF 2: 0.16\n","Pearson correlation for DOF 3: 0.18\n","RMSE for DOF 3: 0.34\n","Pearson correlation for DOF 4: 0.29\n","RMSE for DOF 4: 0.18\n","Pearson correlation for DOF 5: 0.39\n","RMSE for DOF 5: 0.19\n","Pearson correlation for DOF 6: 0.43\n","RMSE for DOF 6: 0.27\n","Pearson correlation for DOF 7: 0.21\n","RMSE for DOF 7: 0.15\n","Pearson correlation for DOF 8: 0.28\n","RMSE for DOF 8: 0.23\n","Pearson correlation for DOF 9: 0.41\n","RMSE for DOF 9: 0.23\n","Pearson correlation for DOF 10: 0.15\n","RMSE for DOF 10: 0.3\n","Pearson correlation for DOF 11: 0.31\n","RMSE for DOF 11: 0.14\n","Pearson correlation for DOF 12: 0.22\n","RMSE for DOF 12: 0.18\n","Pearson correlation for DOF 13: 0.34\n","RMSE for DOF 13: 0.28\n","Pearson correlation for DOF 14: -0.1\n","RMSE for DOF 14: 0.25\n","Pearson correlation for DOF 15: 0.12\n","RMSE for DOF 15: 0.13\n","Pearson correlation for DOF 16: 0.23\n","RMSE for DOF 16: 0.18\n","Pearson correlation for DOF 17: 0.38\n","RMSE for DOF 17: 0.27\n","Pearson correlation for DOF 18: 0.21\n","RMSE for DOF 18: 0.18\n","Pearson correlation for DOF 19: 0.09\n","RMSE for DOF 19: 0.13\n","Pearson correlation for DOF 20: 0.29\n","RMSE for DOF 20: 0.24\n","Pearson correlation for DOF 21: 0.41\n","RMSE for DOF 21: 0.09\n","Pearson correlation for DOF 22: 0.29\n","RMSE for DOF 22: 0.31\n","Final Pearson correlation values: [0.33, 0.04, 0.18, 0.29, 0.39, 0.43, 0.21, 0.28, 0.41, 0.15, 0.31, 0.22, 0.34, -0.1, 0.12, 0.23, 0.38, 0.21, 0.09, 0.29, 0.41, 0.29]\n","Final RMSE values: [0.18, 0.16, 0.34, 0.18, 0.19, 0.27, 0.15, 0.23, 0.23, 0.3, 0.14, 0.18, 0.28, 0.25, 0.13, 0.18, 0.27, 0.18, 0.13, 0.24, 0.09, 0.31]\n"]}],"source":["# Initialize lists for storing CC and RMSE for 22 DOFs\n","pearson = []\n","mse = []\n","\n","# Model testing\n","output_predicted = model.predict(in_test)\n","\n","# Handle sequence length discrepancy if any\n","n = len(out_test) - len(output_predicted)\n","if n == 0:\n","    out_test_final = out_test\n","else:\n","    out_test_final = out_test[:-n, :]\n","\n","# Print shapes for sanity check\n","print(f\"Predicted output shape: {output_predicted.shape}\")\n","print(f\"Actual test output shape: {out_test_final.shape}\")\n","\n","# Calculate Pearson correlation and RMSE for each dimension (1 to 22)\n","for k in range(1, 23):\n","    # Calculate Pearson correlation coefficient\n","    cc_value = np.corrcoef(out_test_final[:, k - 1], output_predicted[:, k - 1])[0, 1]\n","\n","    # Calculate RMSE\n","    rmse_value = math.sqrt(mean_squared_error(out_test_final[:, k - 1], output_predicted[:, k - 1]))\n","\n","    # Store values rounded to two decimal places\n","    pearson.append(round(cc_value, 2))  # Round CC value\n","    mse.append(round(rmse_value, 2))    # Round RMSE value\n","\n","    # Print the rounded values for the current DOF\n","    print(f\"Pearson correlation for DOF {k}: {pearson[-1]}\")\n","    print(f\"RMSE for DOF {k}: {mse[-1]}\")\n","\n","# Print final lists\n","print(f\"Final Pearson correlation values: {pearson}\")\n","print(f\"Final RMSE values: {mse}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNSMAokTnwXIBTim6GAnmcN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}