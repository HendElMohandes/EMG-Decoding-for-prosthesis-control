{"cells":[{"cell_type":"markdown","metadata":{"id":"6SyyKabJWVLG"},"source":["### **Connecting to drive**"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3206,"status":"ok","timestamp":1742554310200,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"k5FyPw9TCS48","outputId":"170d4527-2fb6-4cf9-fbd2-6158f4948e81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Reading the training data Subject\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"zU4qW3h_WMhW"},"source":["### **Importing required Libraries**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1742554310225,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"9unzPdR5Oh3g","outputId":"ebeaddc6-946d-4632-d526-823dbc1a236b"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n"]}],"source":["#Importing all needed libraries\n","import pandas as pd\n","import numpy as np #Matric math\n","import tensorflow as tf #ML\n","from tensorflow.python.framework import ops\n","from random import randint\n","from numpy import array\n","from numpy import argmax\n","import keras.backend as K\n","from tensorflow.keras import models\n","from numpy import array_equal\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Bidirectional\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import TimeDistributed\n","from tensorflow.keras.layers import RepeatVector\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","from scipy.io import loadmat\n","from scipy.io import loadmat\n","\n","# sys.path.append(os.path.abspath(\"/Users/henda/anaconda3/Lib/site-packages\"))\n","# from rnn_utils import *\n","# from public_tests import *\n","ops.reset_default_graph()\n","\n","tf.compat.v1.reset_default_graph() #Clearning cache\n","sess=tf.compat.v1.InteractiveSession()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MK1OHqNaPwOq"},"source":["### **Reading the Dataset**"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1561,"status":"ok","timestamp":1742554311787,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"s-RGR5rLWVAg","outputId":"d8553a62-6b69-40da-a100-7ee15827ebf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["(8969, 119)\n"]}],"source":["data_path = '/content/drive/My Drive/Colab Notebooks/dataset wstimi/8 Features/S40_E1.mat'\n","\n","\n","training_data = loadmat(data_path)\n","\n","Data=training_data[\"Data\"]\n","Data1=np.array(Data)\n","\n","print(Data1.shape)\n","\n","#####################################################\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k5LXXDgjXgvK"},"source":["### **Defining model**"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":846},"executionInfo":{"elapsed":4593,"status":"ok","timestamp":1742554316385,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"cHAfs8h7WtT_","outputId":"e5850682-eb3a-4fd6-96ab-04effc83c9f0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"sequential\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u003cspan style=\"font-weight: bold\"\u003e Layer (type)                         \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Output Shape                \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e         Param # \u003c/span\u003e┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConv1D\u003c/span\u003e)                      │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e32\u003c/span\u003e)              │           \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e9,216\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e32\u003c/span\u003e)              │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBatchNormalization\u003c/span\u003e)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eActivation\u003c/span\u003e)              │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e32\u003c/span\u003e)              │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eMaxPooling1D\u003c/span\u003e)         │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e32\u003c/span\u003e)              │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConv1D\u003c/span\u003e)                    │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)              │           \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e6,144\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)              │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e256\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBatchNormalization\u003c/span\u003e)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eActivation\u003c/span\u003e)            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)              │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eMaxPooling1D\u003c/span\u003e)       │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e64\u003c/span\u003e)              │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eConv1D\u003c/span\u003e)                    │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)             │          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e24,576\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)             │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e512\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBatchNormalization\u003c/span\u003e)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eActivation\u003c/span\u003e)            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)             │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eMaxPooling1D\u003c/span\u003e)       │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e128\u003c/span\u003e)             │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e400\u003c/span\u003e)             │          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e51,600\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBidirectional\u003c/span\u003e)        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2000\u003c/span\u003e)            │      \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e11,208,000\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)                    │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2000\u003c/span\u003e)            │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBidirectional\u003c/span\u003e)      │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2000\u003c/span\u003e)                │      \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e24,008,000\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)                  │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2000\u003c/span\u003e)                │               \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                      │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e22\u003c/span\u003e)                  │          \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e44,022\u003c/span\u003e │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","\u003c/pre\u003e\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m9,216\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │           \u001b[38;5;34m6,144\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,576\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m400\u001b[0m)             │          \u001b[38;5;34m51,600\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m2000\u001b[0m)            │      \u001b[38;5;34m11,208,000\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m2000\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)                │      \u001b[38;5;34m24,008,000\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)                  │          \u001b[38;5;34m44,022\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e35,352,454\u003c/span\u003e (134.86 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,352,454\u001b[0m (134.86 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e35,352,006\u003c/span\u003e (134.86 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,352,006\u001b[0m (134.86 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e448\u003c/span\u003e (1.75 KB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, MaxPooling1D, Dense, Dropout, LSTM, Bidirectional, Add, LayerNormalization, Input, MultiHeadAttention, GlobalAveragePooling1D\n","from tensorflow.keras import activations\n","\n","\n","# Define model input\n","timesteps = 15 # Number of timesteps (sequence length)\n","input_features = 96\n","numResponses = 22\n","\n","# # Function to create a transformer block\n","# def transformer_block(x, head_size, num_heads, dropout, epsilon=1e-6):\n","#     # Multi-head Self Attention\n","#     attention_output = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","#     x = Add()([x, attention_output])  # Residual Connection\n","#     x = LayerNormalization(epsilon=epsilon)(x)\n","\n","#     # Feed-forward network\n","#     x_ff = Dense(head_size, activation='relu')(x)\n","#     x_ff = Dropout(dropout)(x_ff)\n","#     x_ff = Dense(x.shape[-1])(x_ff)\n","#     x = Add()([x, x_ff])  # Residual Connection\n","#     x = LayerNormalization(epsilon=epsilon)(x)\n","\n","#     return x\n","\n","# inputs = Input(shape=(timesteps, input_features))\n","\n","# # 1st convolutional layer\n","# x = Conv1D(32, kernel_size=3, strides=1, padding='same', use_bias=False)(inputs)\n","# x = BatchNormalization()(x)\n","# x = Activation(activations.relu)(x)\n","# x = MaxPooling1D(pool_size=2, strides=1, padding='same')(x)\n","\n","# # 2nd convolutional layer\n","# x = Conv1D(64, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n","# x = BatchNormalization()(x)\n","# x = Activation(activations.relu)(x)\n","# x = MaxPooling1D(pool_size=2, strides=1, padding='same')(x)\n","\n","# # 3rd convolutional layer\n","# x = Conv1D(128, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n","# x = BatchNormalization()(x)\n","# x = Activation(activations.relu)(x)\n","# x = MaxPooling1D(pool_size=2, strides=1, padding='same')(x)\n","\n","\n","# # Add 4 transformer blocks\n","# for _ in range(4):\n","#     x = transformer_block(x, head_size=256, num_heads=4, dropout=0.1, epsilon=1e-6)\n","\n","# # Dense layer before LSTM\n","# x = Dense(400, activation='linear')(x)\n","\n","# # Bidirectional LSTM layers\n","# x = Bidirectional(LSTM(1000, return_sequences=True))(x)\n","# x = Dropout(0.2)(x)\n","# x = Bidirectional(LSTM(1000))(x)\n","# x = Dropout(0.2)(x)\n","\n","# # Final output layer for predicting 22 degrees of freedom (DOFs)\n","# outputs = Dense(numResponses, activation='linear')(x)\n","\n","# # Create model\n","# model = Model(inputs, outputs)\n","\n","# # Print model summary\n","# model.summary()\n","\n","\n","# Define optimized CNN-LSTM architecture\n","model = Sequential()\n","\n","# 1st convolutional layer\n","model.add(Conv1D(32, kernel_size=3, strides=1, padding='same', use_bias=False, input_shape=(timesteps, input_features)))\n","model.add(BatchNormalization())\n","model.add(Activation(activations.relu))\n","model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n","\n","# 2nd convolutional layer\n","model.add(Conv1D(64, kernel_size=3, strides=1, padding='same', use_bias=False))\n","model.add(BatchNormalization())\n","model.add(Activation(activations.relu))\n","model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n","\n","# 3rd convolutional layer\n","model.add(Conv1D(128, kernel_size=3, strides=1, padding='same', use_bias=False))\n","model.add(BatchNormalization())\n","model.add(Activation(activations.relu))\n","model.add(MaxPooling1D(pool_size=2, strides=1, padding='same'))\n","\n","\n","# Dense layer before LSTM\n","model.add(Dense(400, activation='linear'))\n","\n","# Bidirectional LSTM layers\n","model.add(Bidirectional(LSTM(1000, return_sequences=True)))\n","model.add(Dropout(0.2))\n","\n","model.add(Bidirectional(LSTM(1000)))\n","model.add(Dropout(0.2))\n","# Final output layer for predicting 22 degrees of freedom (DOFs)\n","model.add(Dense(numResponses, activation='linear'))  # Adjust the number of outputs for your case (22 DOFs)\n","\n","# Print model summary\n","model.summary()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZUswT6zyX25T"},"source":["### **Entire code and cross validation**"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1742554316423,"user":{"displayName":"hend elmohandes","userId":"08667212620651588699"},"user_tz":-240},"id":"fnzSyeC56B-F"},"outputs":[],"source":["tf.keras.backend.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"aIinOqr3X2uf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Available labels and their counts: {np.float64(0.0): np.int64(5767), np.float64(1.0): np.int64(381), np.float64(2.0): np.int64(216), np.float64(3.0): np.int64(204), np.float64(4.0): np.int64(168), np.float64(5.0): np.int64(153), np.float64(6.0): np.int64(122), np.float64(7.0): np.int64(174), np.float64(8.0): np.int64(165), np.float64(9.0): np.int64(211), np.float64(10.0): np.int64(161), np.float64(11.0): np.int64(194), np.float64(12.0): np.int64(195), np.float64(13.0): np.int64(170), np.float64(14.0): np.int64(153), np.float64(15.0): np.int64(166), np.float64(16.0): np.int64(212), np.float64(17.0): np.int64(157)}\n","Test labels for fold 1: [ 2.  9. 10.  4.]\n","Training input shape: (8213, 96), Training target shape: (8213, 22)\n","Testing input shape: (756, 96), Testing target shape: (756, 22)\n","LSTM training input shape: (8199, 15, 96), LSTM training output shape: (8199, 22)\n","LSTM testing input shape: (742, 15, 96), LSTM testing output shape: (742, 22)\n","Epoch 1/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.2364 - val_loss: 0.0304 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0086 - val_loss: 0.0276 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0062 - val_loss: 0.0308 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0048 - val_loss: 0.0287 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0042 - val_loss: 0.0231 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0258 - learning_rate: 0.0010\n","Epoch 7/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 0.0302 - learning_rate: 0.0010\n","Epoch 8/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0298 - learning_rate: 0.0010\n","Epoch 9/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0261 - learning_rate: 5.0000e-04\n","Epoch 10/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 0.0281 - learning_rate: 5.0000e-04\n","Epoch 11/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 0.0276 - learning_rate: 5.0000e-04\n","Epoch 12/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0275 - learning_rate: 2.5000e-04\n","Epoch 13/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0278 - learning_rate: 2.5000e-04\n","Epoch 14/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0266 - learning_rate: 2.5000e-04\n","Epoch 15/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0270 - learning_rate: 1.2500e-04\n","Epoch 16/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0280 - learning_rate: 1.2500e-04\n","Epoch 17/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0274 - learning_rate: 1.2500e-04\n","Epoch 18/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0277 - learning_rate: 6.2500e-05\n","Epoch 19/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.8648e-04 - val_loss: 0.0270 - learning_rate: 6.2500e-05\n","Epoch 20/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5656e-04 - val_loss: 0.0268 - learning_rate: 6.2500e-05\n","Epoch 21/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4475e-04 - val_loss: 0.0274 - learning_rate: 3.1250e-05\n","Epoch 22/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2982e-04 - val_loss: 0.0279 - learning_rate: 3.1250e-05\n","Epoch 23/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9300e-04 - val_loss: 0.0270 - learning_rate: 3.1250e-05\n","Epoch 24/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9165e-04 - val_loss: 0.0272 - learning_rate: 1.5625e-05\n","Epoch 25/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8141e-04 - val_loss: 0.0274 - learning_rate: 1.5625e-05\n","Epoch 26/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8367e-04 - val_loss: 0.0276 - learning_rate: 1.5625e-05\n","Epoch 27/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6745e-04 - val_loss: 0.0274 - learning_rate: 7.8125e-06\n","Epoch 28/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7440e-04 - val_loss: 0.0276 - learning_rate: 7.8125e-06\n","Epoch 29/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6758e-04 - val_loss: 0.0275 - learning_rate: 7.8125e-06\n","Epoch 30/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7479e-04 - val_loss: 0.0274 - learning_rate: 3.9063e-06\n","Epoch 31/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4872e-04 - val_loss: 0.0275 - learning_rate: 3.9063e-06\n","Epoch 32/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6726e-04 - val_loss: 0.0275 - learning_rate: 3.9063e-06\n","Epoch 33/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.5432e-04 - val_loss: 0.0276 - learning_rate: 1.9531e-06\n","Epoch 34/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6077e-04 - val_loss: 0.0276 - learning_rate: 1.9531e-06\n","Epoch 35/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2812e-04 - val_loss: 0.0276 - learning_rate: 1.9531e-06\n","Epoch 36/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3383e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4116e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3818e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4946e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2671e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3731e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3574e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2823e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3929e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3179e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4165e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2537e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4114e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2221e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3510e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3050e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3301e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4114e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1861e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3315e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3875e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3618e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1924e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2372e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3070e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.4980e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2399e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3271e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3107e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0752e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2825e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0743e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0691e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1158e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1447e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 7.8885e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0644e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0935e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1983e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 7.9862e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0870e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0616e-04 - val_loss: 0.0278 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1527e-04 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1068e-04 - val_loss: 0.0278 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.2116e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0253e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1791e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0314e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.0038e-04 - val_loss: 0.0275 - learning_rate: 1.0000e-06\n","Epoch 85/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.1378e-04 - val_loss: 0.0276 - learning_rate: 1.0000e-06\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n","Predicted output shape: (742, 22)\n","Actual test output shape: (742, 22)\n","Pearson correlation for DOF 1: 0.6\n","RMSE for DOF 1: 0.26\n","Pearson correlation for DOF 2: 0.13\n","RMSE for DOF 2: 0.26\n","Pearson correlation for DOF 3: -0.01\n","RMSE for DOF 3: 0.27\n","Pearson correlation for DOF 4: 0.38\n","RMSE for DOF 4: 0.25\n","Pearson correlation for DOF 5: 0.79\n","RMSE for DOF 5: 0.13\n","Pearson correlation for DOF 6: 0.71\n","RMSE for DOF 6: 0.15\n","Pearson correlation for DOF 7: 0.44\n","RMSE for DOF 7: 0.11\n","Pearson correlation for DOF 8: 0.74\n","RMSE for DOF 8: 0.16\n","Pearson correlation for DOF 9: 0.74\n","RMSE for DOF 9: 0.16\n","Pearson correlation for DOF 10: 0.68\n","RMSE for DOF 10: 0.16\n","Pearson correlation for DOF 11: 0.54\n","RMSE for DOF 11: 0.16\n","Pearson correlation for DOF 12: 0.78\n","RMSE for DOF 12: 0.14\n","Pearson correlation for DOF 13: 0.89\n","RMSE for DOF 13: 0.13\n","Pearson correlation for DOF 14: 0.41\n","RMSE for DOF 14: 0.2\n","Pearson correlation for DOF 15: 0.59\n","RMSE for DOF 15: 0.18\n","Pearson correlation for DOF 16: 0.72\n","RMSE for DOF 16: 0.15\n","Pearson correlation for DOF 17: 0.89\n","RMSE for DOF 17: 0.16\n","Pearson correlation for DOF 18: 0.79\n","RMSE for DOF 18: 0.11\n","Pearson correlation for DOF 19: 0.22\n","RMSE for DOF 19: 0.28\n","Pearson correlation for DOF 20: 0.4\n","RMSE for DOF 20: 0.17\n","Pearson correlation for DOF 21: 0.69\n","RMSE for DOF 21: 0.1\n","Pearson correlation for DOF 22: 0.19\n","RMSE for DOF 22: 0.05\n","Test labels for fold 2: [14.  9.  3. 11.]\n","Training input shape: (8207, 96), Training target shape: (8207, 22)\n","Testing input shape: (762, 96), Testing target shape: (762, 22)\n","LSTM training input shape: (8193, 15, 96), LSTM training output shape: (8193, 22)\n","LSTM testing input shape: (748, 15, 96), LSTM testing output shape: (748, 22)\n","Epoch 1/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.0066 - val_loss: 0.0246 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0242 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 0.0270 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0265 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 0.0254 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0233 - learning_rate: 5.0000e-04\n","Epoch 7/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7428e-04 - val_loss: 0.0244 - learning_rate: 5.0000e-04\n","Epoch 8/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.5857e-04 - val_loss: 0.0258 - learning_rate: 5.0000e-04\n","Epoch 9/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 7.5534e-04 - val_loss: 0.0241 - learning_rate: 5.0000e-04\n","Epoch 10/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 6.5073e-04 - val_loss: 0.0249 - learning_rate: 2.5000e-04\n","Epoch 11/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.6941e-04 - val_loss: 0.0249 - learning_rate: 2.5000e-04\n","Epoch 12/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.5365e-04 - val_loss: 0.0272 - learning_rate: 2.5000e-04\n","Epoch 13/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.0250e-04 - val_loss: 0.0250 - learning_rate: 1.2500e-04\n","Epoch 14/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.5518e-04 - val_loss: 0.0247 - learning_rate: 1.2500e-04\n","Epoch 15/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.4639e-04 - val_loss: 0.0262 - learning_rate: 1.2500e-04\n","Epoch 16/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.2014e-04 - val_loss: 0.0268 - learning_rate: 6.2500e-05\n","Epoch 17/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.1824e-04 - val_loss: 0.0256 - learning_rate: 6.2500e-05\n","Epoch 18/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.0559e-04 - val_loss: 0.0262 - learning_rate: 6.2500e-05\n","Epoch 19/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.8735e-04 - val_loss: 0.0257 - learning_rate: 3.1250e-05\n","Epoch 20/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.7923e-04 - val_loss: 0.0263 - learning_rate: 3.1250e-05\n","Epoch 21/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.7587e-04 - val_loss: 0.0261 - learning_rate: 3.1250e-05\n","Epoch 22/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.7286e-04 - val_loss: 0.0263 - learning_rate: 1.5625e-05\n","Epoch 23/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6673e-04 - val_loss: 0.0263 - learning_rate: 1.5625e-05\n","Epoch 24/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6508e-04 - val_loss: 0.0262 - learning_rate: 1.5625e-05\n","Epoch 25/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.7196e-04 - val_loss: 0.0263 - learning_rate: 7.8125e-06\n","Epoch 26/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5879e-04 - val_loss: 0.0263 - learning_rate: 7.8125e-06\n","Epoch 27/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5396e-04 - val_loss: 0.0263 - learning_rate: 7.8125e-06\n","Epoch 28/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6217e-04 - val_loss: 0.0263 - learning_rate: 3.9063e-06\n","Epoch 29/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5346e-04 - val_loss: 0.0265 - learning_rate: 3.9063e-06\n","Epoch 30/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5332e-04 - val_loss: 0.0262 - learning_rate: 3.9063e-06\n","Epoch 31/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6273e-04 - val_loss: 0.0264 - learning_rate: 1.9531e-06\n","Epoch 32/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6585e-04 - val_loss: 0.0263 - learning_rate: 1.9531e-06\n","Epoch 33/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4778e-04 - val_loss: 0.0263 - learning_rate: 1.9531e-06\n","Epoch 34/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6061e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 35/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5205e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 36/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4677e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5119e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5234e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6048e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5322e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4206e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4759e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5363e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5364e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5035e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5040e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4570e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5094e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4582e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4696e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5106e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5248e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5239e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4657e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5325e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3907e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5378e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4212e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4438e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4983e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4674e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6128e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4681e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4675e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4850e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3942e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4502e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3854e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4721e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4558e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4243e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5072e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4312e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4528e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4295e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3866e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4564e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4538e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5349e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4926e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3617e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4546e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4354e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4265e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","Epoch 85/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5137e-04 - val_loss: 0.0264 - learning_rate: 1.0000e-06\n","Epoch 86/200\n","\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5008e-04 - val_loss: 0.0265 - learning_rate: 1.0000e-06\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n","Predicted output shape: (748, 22)\n","Actual test output shape: (748, 22)\n","Pearson correlation for DOF 1: 0.42\n","RMSE for DOF 1: 0.17\n","Pearson correlation for DOF 2: 0.37\n","RMSE for DOF 2: 0.15\n","Pearson correlation for DOF 3: 0.29\n","RMSE for DOF 3: 0.19\n","Pearson correlation for DOF 4: 0.51\n","RMSE for DOF 4: 0.16\n","Pearson correlation for DOF 5: 0.72\n","RMSE for DOF 5: 0.14\n","Pearson correlation for DOF 6: 0.8\n","RMSE for DOF 6: 0.13\n","Pearson correlation for DOF 7: 0.71\n","RMSE for DOF 7: 0.08\n","Pearson correlation for DOF 8: 0.72\n","RMSE for DOF 8: 0.12\n","Pearson correlation for DOF 9: 0.82\n","RMSE for DOF 9: 0.15\n","Pearson correlation for DOF 10: 0.79\n","RMSE for DOF 10: 0.13\n","Pearson correlation for DOF 11: 0.79\n","RMSE for DOF 11: 0.11\n","Pearson correlation for DOF 12: 0.82\n","RMSE for DOF 12: 0.11\n","Pearson correlation for DOF 13: 0.92\n","RMSE for DOF 13: 0.14\n","Pearson correlation for DOF 14: 0.52\n","RMSE for DOF 14: 0.07\n","Pearson correlation for DOF 15: 0.84\n","RMSE for DOF 15: 0.14\n","Pearson correlation for DOF 16: 0.85\n","RMSE for DOF 16: 0.13\n","Pearson correlation for DOF 17: 0.92\n","RMSE for DOF 17: 0.15\n","Pearson correlation for DOF 18: 0.66\n","RMSE for DOF 18: 0.09\n","Pearson correlation for DOF 19: 0.46\n","RMSE for DOF 19: 0.23\n","Pearson correlation for DOF 20: 0.77\n","RMSE for DOF 20: 0.13\n","Pearson correlation for DOF 21: 0.88\n","RMSE for DOF 21: 0.09\n","Pearson correlation for DOF 22: 0.43\n","RMSE for DOF 22: 0.05\n","Test labels for fold 3: [ 9. 15.  5.  8.]\n","Training input shape: (8274, 96), Training target shape: (8274, 22)\n","Testing input shape: (695, 96), Testing target shape: (695, 22)\n","LSTM training input shape: (8260, 15, 96), LSTM training output shape: (8260, 22)\n","LSTM testing input shape: (681, 15, 96), LSTM testing output shape: (681, 22)\n","Epoch 1/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 0.0159 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0192 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0227 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0156 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0206 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0187 - learning_rate: 0.0010\n","Epoch 7/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0219 - learning_rate: 0.0010\n","Epoch 8/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 6.9034e-04 - val_loss: 0.0194 - learning_rate: 5.0000e-04\n","Epoch 9/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.0828e-04 - val_loss: 0.0180 - learning_rate: 5.0000e-04\n","Epoch 10/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.8493e-04 - val_loss: 0.0166 - learning_rate: 5.0000e-04\n","Epoch 11/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.0887e-04 - val_loss: 0.0179 - learning_rate: 2.5000e-04\n","Epoch 12/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6739e-04 - val_loss: 0.0189 - learning_rate: 2.5000e-04\n","Epoch 13/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6391e-04 - val_loss: 0.0178 - learning_rate: 2.5000e-04\n","Epoch 14/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3015e-04 - val_loss: 0.0182 - learning_rate: 1.2500e-04\n","Epoch 15/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.0993e-04 - val_loss: 0.0197 - learning_rate: 1.2500e-04\n","Epoch 16/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.0556e-04 - val_loss: 0.0177 - learning_rate: 1.2500e-04\n","Epoch 17/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.0048e-04 - val_loss: 0.0185 - learning_rate: 6.2500e-05\n","Epoch 18/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.8768e-04 - val_loss: 0.0177 - learning_rate: 6.2500e-05\n","Epoch 19/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.8475e-04 - val_loss: 0.0179 - learning_rate: 6.2500e-05\n","Epoch 20/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.8504e-04 - val_loss: 0.0179 - learning_rate: 3.1250e-05\n","Epoch 21/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.7362e-04 - val_loss: 0.0179 - learning_rate: 3.1250e-05\n","Epoch 22/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.7184e-04 - val_loss: 0.0183 - learning_rate: 3.1250e-05\n","Epoch 23/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6912e-04 - val_loss: 0.0181 - learning_rate: 1.5625e-05\n","Epoch 24/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.7062e-04 - val_loss: 0.0182 - learning_rate: 1.5625e-05\n","Epoch 25/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6825e-04 - val_loss: 0.0185 - learning_rate: 1.5625e-05\n","Epoch 26/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6902e-04 - val_loss: 0.0182 - learning_rate: 7.8125e-06\n","Epoch 27/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6504e-04 - val_loss: 0.0183 - learning_rate: 7.8125e-06\n","Epoch 28/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6628e-04 - val_loss: 0.0183 - learning_rate: 7.8125e-06\n","Epoch 29/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6143e-04 - val_loss: 0.0182 - learning_rate: 3.9063e-06\n","Epoch 30/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6411e-04 - val_loss: 0.0182 - learning_rate: 3.9063e-06\n","Epoch 31/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6084e-04 - val_loss: 0.0181 - learning_rate: 3.9063e-06\n","Epoch 32/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6092e-04 - val_loss: 0.0181 - learning_rate: 1.9531e-06\n","Epoch 33/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6206e-04 - val_loss: 0.0181 - learning_rate: 1.9531e-06\n","Epoch 34/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5921e-04 - val_loss: 0.0182 - learning_rate: 1.9531e-06\n","Epoch 35/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6213e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 36/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6090e-04 - val_loss: 0.0183 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6099e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6365e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6352e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6381e-04 - val_loss: 0.0181 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6349e-04 - val_loss: 0.0183 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6052e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6415e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5546e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5946e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5815e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6247e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5643e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6602e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6023e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5664e-04 - val_loss: 0.0181 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6222e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5694e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5846e-04 - val_loss: 0.0183 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5893e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6227e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6085e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6000e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5869e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5346e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6179e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5586e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6175e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5802e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5482e-04 - val_loss: 0.0181 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6163e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6205e-04 - val_loss: 0.0183 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6202e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5699e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5215e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5680e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 2.5755e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6003e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5860e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6195e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5656e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5671e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5363e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6254e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6088e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5819e-04 - val_loss: 0.0181 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5115e-04 - val_loss: 0.0181 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5817e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6248e-04 - val_loss: 0.0182 - learning_rate: 1.0000e-06\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n","Predicted output shape: (681, 22)\n","Actual test output shape: (681, 22)\n","Pearson correlation for DOF 1: 0.62\n","RMSE for DOF 1: 0.11\n","Pearson correlation for DOF 2: 0.6\n","RMSE for DOF 2: 0.11\n","Pearson correlation for DOF 3: 0.8\n","RMSE for DOF 3: 0.13\n","Pearson correlation for DOF 4: 0.54\n","RMSE for DOF 4: 0.17\n","Pearson correlation for DOF 5: 0.69\n","RMSE for DOF 5: 0.16\n","Pearson correlation for DOF 6: 0.52\n","RMSE for DOF 6: 0.3\n","Pearson correlation for DOF 7: 0.65\n","RMSE for DOF 7: 0.13\n","Pearson correlation for DOF 8: 0.67\n","RMSE for DOF 8: 0.15\n","Pearson correlation for DOF 9: 0.54\n","RMSE for DOF 9: 0.3\n","Pearson correlation for DOF 10: 0.56\n","RMSE for DOF 10: 0.25\n","Pearson correlation for DOF 11: 0.6\n","RMSE for DOF 11: 0.09\n","Pearson correlation for DOF 12: 0.75\n","RMSE for DOF 12: 0.13\n","Pearson correlation for DOF 13: 0.64\n","RMSE for DOF 13: 0.27\n","Pearson correlation for DOF 14: 0.78\n","RMSE for DOF 14: 0.1\n","Pearson correlation for DOF 15: 0.52\n","RMSE for DOF 15: 0.14\n","Pearson correlation for DOF 16: 0.75\n","RMSE for DOF 16: 0.14\n","Pearson correlation for DOF 17: 0.69\n","RMSE for DOF 17: 0.28\n","Pearson correlation for DOF 18: 0.79\n","RMSE for DOF 18: 0.12\n","Pearson correlation for DOF 19: 0.82\n","RMSE for DOF 19: 0.15\n","Pearson correlation for DOF 20: 0.58\n","RMSE for DOF 20: 0.17\n","Pearson correlation for DOF 21: -0.21\n","RMSE for DOF 21: 0.26\n","Pearson correlation for DOF 22: 0.64\n","RMSE for DOF 22: 0.06\n","Test labels for fold 4: [ 3. 10. 11. 13.]\n","Training input shape: (8240, 96), Training target shape: (8240, 22)\n","Testing input shape: (729, 96), Testing target shape: (729, 22)\n","LSTM training input shape: (8226, 15, 96), LSTM training output shape: (8226, 22)\n","LSTM testing input shape: (715, 15, 96), LSTM testing output shape: (715, 22)\n","Epoch 1/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0306 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.3023e-04 - val_loss: 0.0278 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0291 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 7.9791e-04 - val_loss: 0.0252 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 6.8423e-04 - val_loss: 0.0318 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 6.0397e-04 - val_loss: 0.0268 - learning_rate: 0.0010\n","Epoch 7/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.9989e-04 - val_loss: 0.0287 - learning_rate: 0.0010\n","Epoch 8/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.2398e-04 - val_loss: 0.0259 - learning_rate: 5.0000e-04\n","Epoch 9/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4093e-04 - val_loss: 0.0270 - learning_rate: 5.0000e-04\n","Epoch 10/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.2298e-04 - val_loss: 0.0273 - learning_rate: 5.0000e-04\n","Epoch 11/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.8409e-04 - val_loss: 0.0264 - learning_rate: 2.5000e-04\n","Epoch 12/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6612e-04 - val_loss: 0.0266 - learning_rate: 2.5000e-04\n","Epoch 13/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5982e-04 - val_loss: 0.0259 - learning_rate: 2.5000e-04\n","Epoch 14/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.4734e-04 - val_loss: 0.0262 - learning_rate: 1.2500e-04\n","Epoch 15/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.2774e-04 - val_loss: 0.0258 - learning_rate: 1.2500e-04\n","Epoch 16/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.3109e-04 - val_loss: 0.0266 - learning_rate: 1.2500e-04\n","Epoch 17/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.2086e-04 - val_loss: 0.0263 - learning_rate: 6.2500e-05\n","Epoch 18/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.1726e-04 - val_loss: 0.0261 - learning_rate: 6.2500e-05\n","Epoch 19/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.1274e-04 - val_loss: 0.0258 - learning_rate: 6.2500e-05\n","Epoch 20/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.1002e-04 - val_loss: 0.0261 - learning_rate: 3.1250e-05\n","Epoch 21/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0690e-04 - val_loss: 0.0260 - learning_rate: 3.1250e-05\n","Epoch 22/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0674e-04 - val_loss: 0.0259 - learning_rate: 3.1250e-05\n","Epoch 23/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0664e-04 - val_loss: 0.0261 - learning_rate: 1.5625e-05\n","Epoch 24/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0422e-04 - val_loss: 0.0262 - learning_rate: 1.5625e-05\n","Epoch 25/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0153e-04 - val_loss: 0.0262 - learning_rate: 1.5625e-05\n","Epoch 26/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9866e-04 - val_loss: 0.0263 - learning_rate: 7.8125e-06\n","Epoch 27/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9815e-04 - val_loss: 0.0259 - learning_rate: 7.8125e-06\n","Epoch 28/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9378e-04 - val_loss: 0.0262 - learning_rate: 7.8125e-06\n","Epoch 29/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9729e-04 - val_loss: 0.0261 - learning_rate: 3.9063e-06\n","Epoch 30/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9706e-04 - val_loss: 0.0261 - learning_rate: 3.9063e-06\n","Epoch 31/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9564e-04 - val_loss: 0.0261 - learning_rate: 3.9063e-06\n","Epoch 32/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9625e-04 - val_loss: 0.0261 - learning_rate: 1.9531e-06\n","Epoch 33/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9616e-04 - val_loss: 0.0262 - learning_rate: 1.9531e-06\n","Epoch 34/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9753e-04 - val_loss: 0.0263 - learning_rate: 1.9531e-06\n","Epoch 35/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9805e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 36/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9732e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9937e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0164e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0187e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9383e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9361e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.9809e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0052e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9465e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9914e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9830e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9963e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9441e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9973e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9383e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9138e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9542e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0177e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9815e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9278e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9469e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9617e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9424e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9553e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9267e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.9836e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9585e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9612e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.8868e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9545e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9496e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9844e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9371e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9674e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9465e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9152e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9459e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9221e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9479e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0007e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9666e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9740e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9167e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9651e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9273e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9535e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9519e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9126e-04 - val_loss: 0.0263 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9350e-04 - val_loss: 0.0262 - learning_rate: 1.0000e-06\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n","Predicted output shape: (715, 22)\n","Actual test output shape: (715, 22)\n","Pearson correlation for DOF 1: 0.83\n","RMSE for DOF 1: 0.08\n","Pearson correlation for DOF 2: 0.87\n","RMSE for DOF 2: 0.12\n","Pearson correlation for DOF 3: 0.92\n","RMSE for DOF 3: 0.08\n","Pearson correlation for DOF 4: 0.83\n","RMSE for DOF 4: 0.1\n","Pearson correlation for DOF 5: 0.88\n","RMSE for DOF 5: 0.11\n","Pearson correlation for DOF 6: 0.84\n","RMSE for DOF 6: 0.07\n","Pearson correlation for DOF 7: 0.86\n","RMSE for DOF 7: 0.06\n","Pearson correlation for DOF 8: 0.88\n","RMSE for DOF 8: 0.11\n","Pearson correlation for DOF 9: 0.9\n","RMSE for DOF 9: 0.08\n","Pearson correlation for DOF 10: 0.86\n","RMSE for DOF 10: 0.07\n","Pearson correlation for DOF 11: 0.94\n","RMSE for DOF 11: 0.07\n","Pearson correlation for DOF 12: 0.92\n","RMSE for DOF 12: 0.1\n","Pearson correlation for DOF 13: 0.98\n","RMSE for DOF 13: 0.07\n","Pearson correlation for DOF 14: 0.58\n","RMSE for DOF 14: 0.06\n","Pearson correlation for DOF 15: 0.94\n","RMSE for DOF 15: 0.09\n","Pearson correlation for DOF 16: 0.94\n","RMSE for DOF 16: 0.11\n","Pearson correlation for DOF 17: 0.98\n","RMSE for DOF 17: 0.07\n","Pearson correlation for DOF 18: 0.78\n","RMSE for DOF 18: 0.05\n","Pearson correlation for DOF 19: 0.91\n","RMSE for DOF 19: 0.12\n","Pearson correlation for DOF 20: 0.91\n","RMSE for DOF 20: 0.08\n","Pearson correlation for DOF 21: 0.93\n","RMSE for DOF 21: 0.08\n","Pearson correlation for DOF 22: 0.82\n","RMSE for DOF 22: 0.06\n","Test labels for fold 5: [ 6. 12. 13.  8.]\n","Training input shape: (8317, 96), Training target shape: (8317, 22)\n","Testing input shape: (652, 96), Testing target shape: (652, 22)\n","LSTM training input shape: (8303, 15, 96), LSTM training output shape: (8303, 22)\n","LSTM testing input shape: (638, 15, 96), LSTM testing output shape: (638, 22)\n","Epoch 1/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 8.0606e-04 - val_loss: 0.0283 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.7066e-04 - val_loss: 0.0471 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0307 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 7.1440e-04 - val_loss: 0.0272 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.6734e-04 - val_loss: 0.0259 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.8021e-04 - val_loss: 0.0267 - learning_rate: 0.0010\n","Epoch 7/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.2823e-04 - val_loss: 0.0284 - learning_rate: 0.0010\n","Epoch 8/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.9699e-04 - val_loss: 0.0256 - learning_rate: 0.0010\n","Epoch 9/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.1942e-04 - val_loss: 0.0270 - learning_rate: 0.0010\n","Epoch 10/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.9481e-04 - val_loss: 0.0264 - learning_rate: 0.0010\n","Epoch 11/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.0779e-04 - val_loss: 0.0305 - learning_rate: 0.0010\n","Epoch 12/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.3964e-04 - val_loss: 0.0262 - learning_rate: 5.0000e-04\n","Epoch 13/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6966e-04 - val_loss: 0.0252 - learning_rate: 5.0000e-04\n","Epoch 14/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.4181e-04 - val_loss: 0.0261 - learning_rate: 5.0000e-04\n","Epoch 15/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.3639e-04 - val_loss: 0.0250 - learning_rate: 5.0000e-04\n","Epoch 16/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.2483e-04 - val_loss: 0.0282 - learning_rate: 5.0000e-04\n","Epoch 17/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.3366e-04 - val_loss: 0.0261 - learning_rate: 5.0000e-04\n","Epoch 18/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.2544e-04 - val_loss: 0.0288 - learning_rate: 5.0000e-04\n","Epoch 19/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0027e-04 - val_loss: 0.0261 - learning_rate: 2.5000e-04\n","Epoch 20/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.8046e-04 - val_loss: 0.0279 - learning_rate: 2.5000e-04\n","Epoch 21/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.7843e-04 - val_loss: 0.0267 - learning_rate: 2.5000e-04\n","Epoch 22/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6670e-04 - val_loss: 0.0272 - learning_rate: 1.2500e-04\n","Epoch 23/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6227e-04 - val_loss: 0.0270 - learning_rate: 1.2500e-04\n","Epoch 24/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6372e-04 - val_loss: 0.0266 - learning_rate: 1.2500e-04\n","Epoch 25/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5758e-04 - val_loss: 0.0268 - learning_rate: 6.2500e-05\n","Epoch 26/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4882e-04 - val_loss: 0.0272 - learning_rate: 6.2500e-05\n","Epoch 27/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5137e-04 - val_loss: 0.0267 - learning_rate: 6.2500e-05\n","Epoch 28/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4341e-04 - val_loss: 0.0268 - learning_rate: 3.1250e-05\n","Epoch 29/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4635e-04 - val_loss: 0.0266 - learning_rate: 3.1250e-05\n","Epoch 30/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4604e-04 - val_loss: 0.0268 - learning_rate: 3.1250e-05\n","Epoch 31/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4373e-04 - val_loss: 0.0268 - learning_rate: 1.5625e-05\n","Epoch 32/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4400e-04 - val_loss: 0.0269 - learning_rate: 1.5625e-05\n","Epoch 33/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4436e-04 - val_loss: 0.0268 - learning_rate: 1.5625e-05\n","Epoch 34/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4398e-04 - val_loss: 0.0267 - learning_rate: 7.8125e-06\n","Epoch 35/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4110e-04 - val_loss: 0.0268 - learning_rate: 7.8125e-06\n","Epoch 36/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3941e-04 - val_loss: 0.0267 - learning_rate: 7.8125e-06\n","Epoch 37/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3842e-04 - val_loss: 0.0267 - learning_rate: 3.9063e-06\n","Epoch 38/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4315e-04 - val_loss: 0.0268 - learning_rate: 3.9063e-06\n","Epoch 39/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4195e-04 - val_loss: 0.0267 - learning_rate: 3.9063e-06\n","Epoch 40/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4023e-04 - val_loss: 0.0267 - learning_rate: 1.9531e-06\n","Epoch 41/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4120e-04 - val_loss: 0.0268 - learning_rate: 1.9531e-06\n","Epoch 42/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4338e-04 - val_loss: 0.0267 - learning_rate: 1.9531e-06\n","Epoch 43/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4382e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3966e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4329e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4108e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3992e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4111e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4165e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4371e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3879e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4125e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4044e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4379e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3902e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4166e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4341e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4191e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3645e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4019e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4117e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3845e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4217e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4045e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4389e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4388e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3856e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.4042e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4078e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4222e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4392e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4048e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3981e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4118e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3806e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3861e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3632e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3999e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4199e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3721e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4130e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4272e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4020e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3860e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 85/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3938e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 86/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3636e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 87/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4157e-04 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 88/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3863e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 89/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3801e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 90/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3985e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 91/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4260e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 92/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3812e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 93/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3984e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 94/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3945e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 95/200\n","\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3762e-04 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n","Predicted output shape: (638, 22)\n","Actual test output shape: (638, 22)\n","Pearson correlation for DOF 1: 0.93\n","RMSE for DOF 1: 0.08\n","Pearson correlation for DOF 2: 0.86\n","RMSE for DOF 2: 0.08\n","Pearson correlation for DOF 3: 0.67\n","RMSE for DOF 3: 0.13\n","Pearson correlation for DOF 4: 0.92\n","RMSE for DOF 4: 0.12\n","Pearson correlation for DOF 5: 0.91\n","RMSE for DOF 5: 0.12\n","Pearson correlation for DOF 6: 0.97\n","RMSE for DOF 6: 0.08\n","Pearson correlation for DOF 7: 0.93\n","RMSE for DOF 7: 0.09\n","Pearson correlation for DOF 8: 0.9\n","RMSE for DOF 8: 0.11\n","Pearson correlation for DOF 9: 0.96\n","RMSE for DOF 9: 0.09\n","Pearson correlation for DOF 10: 0.94\n","RMSE for DOF 10: 0.11\n","Pearson correlation for DOF 11: 0.94\n","RMSE for DOF 11: 0.07\n","Pearson correlation for DOF 12: 0.92\n","RMSE for DOF 12: 0.09\n","Pearson correlation for DOF 13: 0.96\n","RMSE for DOF 13: 0.08\n","Pearson correlation for DOF 14: 0.92\n","RMSE for DOF 14: 0.06\n","Pearson correlation for DOF 15: 0.78\n","RMSE for DOF 15: 0.06\n","Pearson correlation for DOF 16: 0.94\n","RMSE for DOF 16: 0.09\n","Pearson correlation for DOF 17: 0.95\n","RMSE for DOF 17: 0.09\n","Pearson correlation for DOF 18: 0.97\n","RMSE for DOF 18: 0.08\n","Pearson correlation for DOF 19: 0.94\n","RMSE for DOF 19: 0.05\n","Pearson correlation for DOF 20: 0.84\n","RMSE for DOF 20: 0.12\n","Pearson correlation for DOF 21: 0.86\n","RMSE for DOF 21: 0.07\n","Pearson correlation for DOF 22: 0.88\n","RMSE for DOF 22: 0.09\n","Test labels for fold 6: [ 1.  3.  4. 17.]\n","Training input shape: (8059, 96), Training target shape: (8059, 22)\n","Testing input shape: (910, 96), Testing target shape: (910, 22)\n","LSTM training input shape: (8045, 15, 96), LSTM training output shape: (8045, 22)\n","LSTM testing input shape: (896, 15, 96), LSTM testing output shape: (896, 22)\n","Epoch 1/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 5.6583e-04 - val_loss: 0.0305 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 6.0189e-04 - val_loss: 0.0274 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 6.6627e-04 - val_loss: 0.0285 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0249 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.7322e-04 - val_loss: 0.0249 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.2768e-04 - val_loss: 0.0268 - learning_rate: 0.0010\n","Epoch 7/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.4861e-04 - val_loss: 0.0246 - learning_rate: 0.0010\n","Epoch 8/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.1065e-04 - val_loss: 0.0248 - learning_rate: 0.0010\n","Epoch 9/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.9640e-04 - val_loss: 0.0275 - learning_rate: 0.0010\n","Epoch 10/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.4944e-04 - val_loss: 0.0245 - learning_rate: 0.0010\n","Epoch 11/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6672e-04 - val_loss: 0.0254 - learning_rate: 0.0010\n","Epoch 12/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.1072e-04 - val_loss: 0.0260 - learning_rate: 0.0010\n","Epoch 13/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.6901e-04 - val_loss: 0.0249 - learning_rate: 0.0010\n","Epoch 14/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5852e-04 - val_loss: 0.0253 - learning_rate: 5.0000e-04\n","Epoch 15/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9742e-04 - val_loss: 0.0246 - learning_rate: 5.0000e-04\n","Epoch 16/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0052e-04 - val_loss: 0.0247 - learning_rate: 5.0000e-04\n","Epoch 17/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.4001e-04 - val_loss: 0.0258 - learning_rate: 2.5000e-04\n","Epoch 18/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6436e-04 - val_loss: 0.0268 - learning_rate: 2.5000e-04\n","Epoch 19/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6458e-04 - val_loss: 0.0255 - learning_rate: 2.5000e-04\n","Epoch 20/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5265e-04 - val_loss: 0.0252 - learning_rate: 1.2500e-04\n","Epoch 21/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5059e-04 - val_loss: 0.0259 - learning_rate: 1.2500e-04\n","Epoch 22/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4461e-04 - val_loss: 0.0254 - learning_rate: 1.2500e-04\n","Epoch 23/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3869e-04 - val_loss: 0.0257 - learning_rate: 6.2500e-05\n","Epoch 24/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3627e-04 - val_loss: 0.0255 - learning_rate: 6.2500e-05\n","Epoch 25/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3986e-04 - val_loss: 0.0255 - learning_rate: 6.2500e-05\n","Epoch 26/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3474e-04 - val_loss: 0.0255 - learning_rate: 3.1250e-05\n","Epoch 27/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2921e-04 - val_loss: 0.0258 - learning_rate: 3.1250e-05\n","Epoch 28/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3337e-04 - val_loss: 0.0260 - learning_rate: 3.1250e-05\n","Epoch 29/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3118e-04 - val_loss: 0.0258 - learning_rate: 1.5625e-05\n","Epoch 30/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2941e-04 - val_loss: 0.0257 - learning_rate: 1.5625e-05\n","Epoch 31/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2927e-04 - val_loss: 0.0258 - learning_rate: 1.5625e-05\n","Epoch 32/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2625e-04 - val_loss: 0.0259 - learning_rate: 7.8125e-06\n","Epoch 33/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2882e-04 - val_loss: 0.0258 - learning_rate: 7.8125e-06\n","Epoch 34/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2621e-04 - val_loss: 0.0257 - learning_rate: 7.8125e-06\n","Epoch 35/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2636e-04 - val_loss: 0.0258 - learning_rate: 3.9063e-06\n","Epoch 36/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2785e-04 - val_loss: 0.0258 - learning_rate: 3.9063e-06\n","Epoch 37/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2994e-04 - val_loss: 0.0258 - learning_rate: 3.9063e-06\n","Epoch 38/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2719e-04 - val_loss: 0.0259 - learning_rate: 1.9531e-06\n","Epoch 39/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2596e-04 - val_loss: 0.0258 - learning_rate: 1.9531e-06\n","Epoch 40/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2583e-04 - val_loss: 0.0259 - learning_rate: 1.9531e-06\n","Epoch 41/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2638e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2854e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2565e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2736e-04 - val_loss: 0.0259 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2830e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2435e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2670e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2695e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2798e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2802e-04 - val_loss: 0.0259 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2906e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2682e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2819e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2698e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2633e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2530e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2467e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2540e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2633e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2546e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2505e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2525e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2807e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2556e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2495e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2406e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2224e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2647e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2854e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2335e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2441e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2419e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2353e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2748e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2800e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2697e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2503e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2821e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2583e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2724e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2512e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2498e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2472e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2459e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 85/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2282e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 86/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2651e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","Epoch 87/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2758e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 88/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2634e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 89/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2508e-04 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n","Epoch 90/200\n","\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2733e-04 - val_loss: 0.0258 - learning_rate: 1.0000e-06\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n","Predicted output shape: (896, 22)\n","Actual test output shape: (896, 22)\n","Pearson correlation for DOF 1: 0.82\n","RMSE for DOF 1: 0.1\n","Pearson correlation for DOF 2: 0.86\n","RMSE for DOF 2: 0.14\n","Pearson correlation for DOF 3: 0.59\n","RMSE for DOF 3: 0.19\n","Pearson correlation for DOF 4: 0.79\n","RMSE for DOF 4: 0.11\n","Pearson correlation for DOF 5: 0.97\n","RMSE for DOF 5: 0.09\n","Pearson correlation for DOF 6: 0.98\n","RMSE for DOF 6: 0.07\n","Pearson correlation for DOF 7: 0.86\n","RMSE for DOF 7: 0.08\n","Pearson correlation for DOF 8: 0.96\n","RMSE for DOF 8: 0.09\n","Pearson correlation for DOF 9: 0.98\n","RMSE for DOF 9: 0.07\n","Pearson correlation for DOF 10: 0.96\n","RMSE for DOF 10: 0.09\n","Pearson correlation for DOF 11: 0.9\n","RMSE for DOF 11: 0.07\n","Pearson correlation for DOF 12: 0.96\n","RMSE for DOF 12: 0.07\n","Pearson correlation for DOF 13: 0.98\n","RMSE for DOF 13: 0.07\n","Pearson correlation for DOF 14: 0.85\n","RMSE for DOF 14: 0.07\n","Pearson correlation for DOF 15: 0.97\n","RMSE for DOF 15: 0.06\n","Pearson correlation for DOF 16: 0.98\n","RMSE for DOF 16: 0.06\n","Pearson correlation for DOF 17: 0.99\n","RMSE for DOF 17: 0.06\n","Pearson correlation for DOF 18: 0.98\n","RMSE for DOF 18: 0.06\n","Pearson correlation for DOF 19: 0.89\n","RMSE for DOF 19: 0.07\n","Pearson correlation for DOF 20: 0.85\n","RMSE for DOF 20: 0.12\n","Pearson correlation for DOF 21: 0.9\n","RMSE for DOF 21: 0.08\n","Pearson correlation for DOF 22: 0.78\n","RMSE for DOF 22: 0.19\n","Test labels for fold 7: [ 5. 12.  2. 17.]\n","Training input shape: (8248, 96), Training target shape: (8248, 22)\n","Testing input shape: (721, 96), Testing target shape: (721, 22)\n","LSTM training input shape: (8234, 15, 96), LSTM training output shape: (8234, 22)\n","LSTM testing input shape: (707, 15, 96), LSTM testing output shape: (707, 22)\n","Epoch 1/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 4.8827e-04 - val_loss: 0.0255 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.1698e-04 - val_loss: 0.0244 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.0570e-04 - val_loss: 0.0245 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.5930e-04 - val_loss: 0.0279 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.9408e-04 - val_loss: 0.0279 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.9894e-04 - val_loss: 0.0266 - learning_rate: 5.0000e-04\n","Epoch 7/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.9981e-04 - val_loss: 0.0251 - learning_rate: 5.0000e-04\n","Epoch 8/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.8842e-04 - val_loss: 0.0257 - learning_rate: 5.0000e-04\n","Epoch 9/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6193e-04 - val_loss: 0.0252 - learning_rate: 2.5000e-04\n","Epoch 10/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5107e-04 - val_loss: 0.0240 - learning_rate: 2.5000e-04\n","Epoch 11/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4624e-04 - val_loss: 0.0251 - learning_rate: 2.5000e-04\n","Epoch 12/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4276e-04 - val_loss: 0.0251 - learning_rate: 2.5000e-04\n","Epoch 13/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3769e-04 - val_loss: 0.0250 - learning_rate: 2.5000e-04\n","Epoch 14/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3033e-04 - val_loss: 0.0242 - learning_rate: 1.2500e-04\n","Epoch 15/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2617e-04 - val_loss: 0.0244 - learning_rate: 1.2500e-04\n","Epoch 16/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2651e-04 - val_loss: 0.0241 - learning_rate: 1.2500e-04\n","Epoch 17/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2500e-04 - val_loss: 0.0249 - learning_rate: 6.2500e-05\n","Epoch 18/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1893e-04 - val_loss: 0.0249 - learning_rate: 6.2500e-05\n","Epoch 19/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1985e-04 - val_loss: 0.0249 - learning_rate: 6.2500e-05\n","Epoch 20/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1621e-04 - val_loss: 0.0248 - learning_rate: 3.1250e-05\n","Epoch 21/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1746e-04 - val_loss: 0.0248 - learning_rate: 3.1250e-05\n","Epoch 22/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1597e-04 - val_loss: 0.0248 - learning_rate: 3.1250e-05\n","Epoch 23/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1727e-04 - val_loss: 0.0250 - learning_rate: 1.5625e-05\n","Epoch 24/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1246e-04 - val_loss: 0.0249 - learning_rate: 1.5625e-05\n","Epoch 25/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1401e-04 - val_loss: 0.0251 - learning_rate: 1.5625e-05\n","Epoch 26/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1436e-04 - val_loss: 0.0249 - learning_rate: 7.8125e-06\n","Epoch 27/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1327e-04 - val_loss: 0.0248 - learning_rate: 7.8125e-06\n","Epoch 28/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1195e-04 - val_loss: 0.0248 - learning_rate: 7.8125e-06\n","Epoch 29/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1269e-04 - val_loss: 0.0248 - learning_rate: 3.9063e-06\n","Epoch 30/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1297e-04 - val_loss: 0.0248 - learning_rate: 3.9063e-06\n","Epoch 31/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1167e-04 - val_loss: 0.0248 - learning_rate: 3.9063e-06\n","Epoch 32/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1405e-04 - val_loss: 0.0248 - learning_rate: 1.9531e-06\n","Epoch 33/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1073e-04 - val_loss: 0.0249 - learning_rate: 1.9531e-06\n","Epoch 34/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1563e-04 - val_loss: 0.0248 - learning_rate: 1.9531e-06\n","Epoch 35/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1191e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 36/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1328e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1321e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1214e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1095e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1133e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1450e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1515e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1373e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1212e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1292e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1371e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1089e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1110e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.1377e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1454e-04 - val_loss: 0.0250 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.1148e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1198e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1334e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1305e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1057e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1348e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1344e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.1138e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 1.1148e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1245e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1360e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1593e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1576e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1063e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1189e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1414e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0951e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1197e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1331e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1015e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1030e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1178e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1343e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1350e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1190e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1164e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1269e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1173e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1193e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1445e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1168e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1178e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1519e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1128e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 85/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1258e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 86/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1222e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 87/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0798e-04 - val_loss: 0.0248 - learning_rate: 1.0000e-06\n","Epoch 88/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1280e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 89/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1009e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","Epoch 90/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1027e-04 - val_loss: 0.0249 - learning_rate: 1.0000e-06\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n","Predicted output shape: (707, 22)\n","Actual test output shape: (707, 22)\n","Pearson correlation for DOF 1: 0.96\n","RMSE for DOF 1: 0.07\n","Pearson correlation for DOF 2: 0.62\n","RMSE for DOF 2: 0.14\n","Pearson correlation for DOF 3: 0.66\n","RMSE for DOF 3: 0.2\n","Pearson correlation for DOF 4: 0.92\n","RMSE for DOF 4: 0.11\n","Pearson correlation for DOF 5: 0.71\n","RMSE for DOF 5: 0.11\n","Pearson correlation for DOF 6: 0.88\n","RMSE for DOF 6: 0.11\n","Pearson correlation for DOF 7: 0.74\n","RMSE for DOF 7: 0.1\n","Pearson correlation for DOF 8: 0.7\n","RMSE for DOF 8: 0.12\n","Pearson correlation for DOF 9: 0.93\n","RMSE for DOF 9: 0.1\n","Pearson correlation for DOF 10: 0.89\n","RMSE for DOF 10: 0.09\n","Pearson correlation for DOF 11: 0.96\n","RMSE for DOF 11: 0.05\n","Pearson correlation for DOF 12: 0.84\n","RMSE for DOF 12: 0.08\n","Pearson correlation for DOF 13: 0.98\n","RMSE for DOF 13: 0.07\n","Pearson correlation for DOF 14: 0.94\n","RMSE for DOF 14: 0.08\n","Pearson correlation for DOF 15: 0.96\n","RMSE for DOF 15: 0.06\n","Pearson correlation for DOF 16: 0.9\n","RMSE for DOF 16: 0.06\n","Pearson correlation for DOF 17: 0.98\n","RMSE for DOF 17: 0.07\n","Pearson correlation for DOF 18: 0.95\n","RMSE for DOF 18: 0.05\n","Pearson correlation for DOF 19: 0.93\n","RMSE for DOF 19: 0.09\n","Pearson correlation for DOF 20: 0.78\n","RMSE for DOF 20: 0.14\n","Pearson correlation for DOF 21: 0.84\n","RMSE for DOF 21: 0.08\n","Pearson correlation for DOF 22: 0.68\n","RMSE for DOF 22: 0.23\n","Test labels for fold 8: [10.  2.  6. 11.]\n","Training input shape: (8276, 96), Training target shape: (8276, 22)\n","Testing input shape: (693, 96), Testing target shape: (693, 22)\n","LSTM training input shape: (8262, 15, 96), LSTM training output shape: (8262, 22)\n","LSTM testing input shape: (679, 15, 96), LSTM testing output shape: (679, 22)\n","Epoch 1/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 2.9427e-04 - val_loss: 0.0290 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.1308e-04 - val_loss: 0.0290 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.3869e-04 - val_loss: 0.0371 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 5.7802e-04 - val_loss: 0.0325 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6204e-04 - val_loss: 0.0288 - learning_rate: 5.0000e-04\n","Epoch 6/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.8313e-04 - val_loss: 0.0278 - learning_rate: 5.0000e-04\n","Epoch 7/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6435e-04 - val_loss: 0.0281 - learning_rate: 5.0000e-04\n","Epoch 8/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6333e-04 - val_loss: 0.0278 - learning_rate: 5.0000e-04\n","Epoch 9/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.6301e-04 - val_loss: 0.0277 - learning_rate: 5.0000e-04\n","Epoch 10/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4848e-04 - val_loss: 0.0274 - learning_rate: 5.0000e-04\n","Epoch 11/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.5502e-04 - val_loss: 0.0274 - learning_rate: 5.0000e-04\n","Epoch 12/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4716e-04 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n","Epoch 13/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4878e-04 - val_loss: 0.0277 - learning_rate: 5.0000e-04\n","Epoch 14/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3618e-04 - val_loss: 0.0267 - learning_rate: 2.5000e-04\n","Epoch 15/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2132e-04 - val_loss: 0.0273 - learning_rate: 2.5000e-04\n","Epoch 16/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.2708e-04 - val_loss: 0.0268 - learning_rate: 2.5000e-04\n","Epoch 17/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1892e-04 - val_loss: 0.0271 - learning_rate: 2.5000e-04\n","Epoch 18/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1245e-04 - val_loss: 0.0270 - learning_rate: 1.2500e-04\n","Epoch 19/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0570e-04 - val_loss: 0.0264 - learning_rate: 1.2500e-04\n","Epoch 20/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0292e-04 - val_loss: 0.0267 - learning_rate: 1.2500e-04\n","Epoch 21/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0386e-04 - val_loss: 0.0268 - learning_rate: 1.2500e-04\n","Epoch 22/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0297e-04 - val_loss: 0.0273 - learning_rate: 1.2500e-04\n","Epoch 23/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.9496e-05 - val_loss: 0.0270 - learning_rate: 6.2500e-05\n","Epoch 24/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.7990e-05 - val_loss: 0.0265 - learning_rate: 6.2500e-05\n","Epoch 25/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.8069e-05 - val_loss: 0.0271 - learning_rate: 6.2500e-05\n","Epoch 26/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4395e-05 - val_loss: 0.0269 - learning_rate: 3.1250e-05\n","Epoch 27/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5404e-05 - val_loss: 0.0266 - learning_rate: 3.1250e-05\n","Epoch 28/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4464e-05 - val_loss: 0.0268 - learning_rate: 3.1250e-05\n","Epoch 29/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5005e-05 - val_loss: 0.0267 - learning_rate: 1.5625e-05\n","Epoch 30/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5822e-05 - val_loss: 0.0267 - learning_rate: 1.5625e-05\n","Epoch 31/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5913e-05 - val_loss: 0.0268 - learning_rate: 1.5625e-05\n","Epoch 32/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4062e-05 - val_loss: 0.0268 - learning_rate: 7.8125e-06\n","Epoch 33/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5132e-05 - val_loss: 0.0268 - learning_rate: 7.8125e-06\n","Epoch 34/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3342e-05 - val_loss: 0.0268 - learning_rate: 7.8125e-06\n","Epoch 35/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.7601e-05 - val_loss: 0.0267 - learning_rate: 3.9063e-06\n","Epoch 36/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4522e-05 - val_loss: 0.0267 - learning_rate: 3.9063e-06\n","Epoch 37/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4084e-05 - val_loss: 0.0268 - learning_rate: 3.9063e-06\n","Epoch 38/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2588e-05 - val_loss: 0.0268 - learning_rate: 1.9531e-06\n","Epoch 39/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2625e-05 - val_loss: 0.0268 - learning_rate: 1.9531e-06\n","Epoch 40/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1354e-05 - val_loss: 0.0268 - learning_rate: 1.9531e-06\n","Epoch 41/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3903e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4673e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1639e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2430e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4084e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5373e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4230e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1862e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0298e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3649e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0082e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1536e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3680e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1825e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5843e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3523e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4105e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3483e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2528e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4567e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2522e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3742e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2833e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5902e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2612e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1680e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2891e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1847e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2557e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1472e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9072e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2078e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2439e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3180e-05 - val_loss: 0.0269 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2094e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2880e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2928e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0498e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4454e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1424e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2752e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2066e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 83/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3409e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 84/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2369e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 85/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2083e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 86/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2405e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 87/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4231e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 88/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9867e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 89/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1685e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 90/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1711e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 91/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3821e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 92/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1834e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 93/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2503e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 94/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8578e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 95/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1120e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 96/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3977e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 97/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3222e-05 - val_loss: 0.0267 - learning_rate: 1.0000e-06\n","Epoch 98/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3074e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","Epoch 99/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3073e-05 - val_loss: 0.0268 - learning_rate: 1.0000e-06\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n","Predicted output shape: (679, 22)\n","Actual test output shape: (679, 22)\n","Pearson correlation for DOF 1: 0.95\n","RMSE for DOF 1: 0.08\n","Pearson correlation for DOF 2: 0.94\n","RMSE for DOF 2: 0.08\n","Pearson correlation for DOF 3: 0.95\n","RMSE for DOF 3: 0.08\n","Pearson correlation for DOF 4: 0.94\n","RMSE for DOF 4: 0.08\n","Pearson correlation for DOF 5: 0.96\n","RMSE for DOF 5: 0.08\n","Pearson correlation for DOF 6: 0.94\n","RMSE for DOF 6: 0.12\n","Pearson correlation for DOF 7: 0.93\n","RMSE for DOF 7: 0.09\n","Pearson correlation for DOF 8: 0.95\n","RMSE for DOF 8: 0.09\n","Pearson correlation for DOF 9: 0.96\n","RMSE for DOF 9: 0.1\n","Pearson correlation for DOF 10: 0.97\n","RMSE for DOF 10: 0.08\n","Pearson correlation for DOF 11: 0.97\n","RMSE for DOF 11: 0.04\n","Pearson correlation for DOF 12: 0.97\n","RMSE for DOF 12: 0.06\n","Pearson correlation for DOF 13: 0.98\n","RMSE for DOF 13: 0.06\n","Pearson correlation for DOF 14: 0.91\n","RMSE for DOF 14: 0.09\n","Pearson correlation for DOF 15: 0.96\n","RMSE for DOF 15: 0.05\n","Pearson correlation for DOF 16: 0.97\n","RMSE for DOF 16: 0.06\n","Pearson correlation for DOF 17: 0.98\n","RMSE for DOF 17: 0.07\n","Pearson correlation for DOF 18: 0.96\n","RMSE for DOF 18: 0.08\n","Pearson correlation for DOF 19: 0.95\n","RMSE for DOF 19: 0.07\n","Pearson correlation for DOF 20: 0.8\n","RMSE for DOF 20: 0.1\n","Pearson correlation for DOF 21: 0.95\n","RMSE for DOF 21: 0.04\n","Pearson correlation for DOF 22: 0.91\n","RMSE for DOF 22: 0.03\n","Test labels for fold 9: [14.  7. 17.  9.]\n","Training input shape: (8274, 96), Training target shape: (8274, 22)\n","Testing input shape: (695, 96), Testing target shape: (695, 22)\n","LSTM training input shape: (8260, 15, 96), LSTM training output shape: (8260, 22)\n","LSTM testing input shape: (681, 15, 96), LSTM testing output shape: (681, 22)\n","Epoch 1/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 4.1236e-04 - val_loss: 0.0272 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6325e-04 - val_loss: 0.0221 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6322e-04 - val_loss: 0.0258 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.7442e-04 - val_loss: 0.0263 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.5539e-04 - val_loss: 0.0291 - learning_rate: 0.0010\n","Epoch 6/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.8664e-04 - val_loss: 0.0235 - learning_rate: 5.0000e-04\n","Epoch 7/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4798e-04 - val_loss: 0.0290 - learning_rate: 5.0000e-04\n","Epoch 8/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0937e-04 - val_loss: 0.0234 - learning_rate: 5.0000e-04\n","Epoch 9/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3281e-04 - val_loss: 0.0240 - learning_rate: 2.5000e-04\n","Epoch 10/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1861e-04 - val_loss: 0.0233 - learning_rate: 2.5000e-04\n","Epoch 11/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1791e-04 - val_loss: 0.0232 - learning_rate: 2.5000e-04\n","Epoch 12/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0720e-04 - val_loss: 0.0233 - learning_rate: 1.2500e-04\n","Epoch 13/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0218e-04 - val_loss: 0.0230 - learning_rate: 1.2500e-04\n","Epoch 14/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0626e-04 - val_loss: 0.0235 - learning_rate: 1.2500e-04\n","Epoch 15/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0288e-04 - val_loss: 0.0232 - learning_rate: 6.2500e-05\n","Epoch 16/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0111e-04 - val_loss: 0.0233 - learning_rate: 6.2500e-05\n","Epoch 17/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0121e-04 - val_loss: 0.0234 - learning_rate: 6.2500e-05\n","Epoch 18/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5963e-05 - val_loss: 0.0233 - learning_rate: 3.1250e-05\n","Epoch 19/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5694e-05 - val_loss: 0.0233 - learning_rate: 3.1250e-05\n","Epoch 20/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.6499e-05 - val_loss: 0.0234 - learning_rate: 3.1250e-05\n","Epoch 21/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.6181e-05 - val_loss: 0.0233 - learning_rate: 1.5625e-05\n","Epoch 22/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4963e-05 - val_loss: 0.0234 - learning_rate: 1.5625e-05\n","Epoch 23/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5189e-05 - val_loss: 0.0233 - learning_rate: 1.5625e-05\n","Epoch 24/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4460e-05 - val_loss: 0.0232 - learning_rate: 7.8125e-06\n","Epoch 25/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.6791e-05 - val_loss: 0.0233 - learning_rate: 7.8125e-06\n","Epoch 26/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3943e-05 - val_loss: 0.0232 - learning_rate: 7.8125e-06\n","Epoch 27/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2740e-05 - val_loss: 0.0234 - learning_rate: 3.9063e-06\n","Epoch 28/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4256e-05 - val_loss: 0.0233 - learning_rate: 3.9063e-06\n","Epoch 29/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4883e-05 - val_loss: 0.0233 - learning_rate: 3.9063e-06\n","Epoch 30/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3611e-05 - val_loss: 0.0233 - learning_rate: 1.9531e-06\n","Epoch 31/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3477e-05 - val_loss: 0.0233 - learning_rate: 1.9531e-06\n","Epoch 32/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2358e-05 - val_loss: 0.0233 - learning_rate: 1.9531e-06\n","Epoch 33/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2259e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 34/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2824e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 35/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4637e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 36/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2684e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1109e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4286e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4203e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5379e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2656e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4463e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3868e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4490e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4099e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5869e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1458e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2766e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4272e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4072e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2469e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4393e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4795e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1969e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4509e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2777e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2898e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2982e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5920e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4384e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3729e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4881e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5409e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3704e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4278e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3288e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.6977e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2928e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4391e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2578e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4397e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4886e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3116e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3600e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.6042e-05 - val_loss: 0.0234 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2946e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4218e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2409e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4436e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1344e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.6048e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","Epoch 82/200\n","\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4692e-05 - val_loss: 0.0233 - learning_rate: 1.0000e-06\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n","Predicted output shape: (681, 22)\n","Actual test output shape: (681, 22)\n","Pearson correlation for DOF 1: 0.97\n","RMSE for DOF 1: 0.07\n","Pearson correlation for DOF 2: 0.67\n","RMSE for DOF 2: 0.12\n","Pearson correlation for DOF 3: 0.53\n","RMSE for DOF 3: 0.2\n","Pearson correlation for DOF 4: 0.92\n","RMSE for DOF 4: 0.1\n","Pearson correlation for DOF 5: 0.82\n","RMSE for DOF 5: 0.12\n","Pearson correlation for DOF 6: 0.74\n","RMSE for DOF 6: 0.15\n","Pearson correlation for DOF 7: 0.82\n","RMSE for DOF 7: 0.07\n","Pearson correlation for DOF 8: 0.88\n","RMSE for DOF 8: 0.1\n","Pearson correlation for DOF 9: 0.97\n","RMSE for DOF 9: 0.08\n","Pearson correlation for DOF 10: 0.94\n","RMSE for DOF 10: 0.1\n","Pearson correlation for DOF 11: 0.94\n","RMSE for DOF 11: 0.11\n","Pearson correlation for DOF 12: 0.9\n","RMSE for DOF 12: 0.08\n","Pearson correlation for DOF 13: 0.97\n","RMSE for DOF 13: 0.08\n","Pearson correlation for DOF 14: 0.81\n","RMSE for DOF 14: 0.05\n","Pearson correlation for DOF 15: 0.94\n","RMSE for DOF 15: 0.04\n","Pearson correlation for DOF 16: 0.91\n","RMSE for DOF 16: 0.06\n","Pearson correlation for DOF 17: 0.97\n","RMSE for DOF 17: 0.07\n","Pearson correlation for DOF 18: 0.97\n","RMSE for DOF 18: 0.05\n","Pearson correlation for DOF 19: 0.94\n","RMSE for DOF 19: 0.08\n","Pearson correlation for DOF 20: 0.71\n","RMSE for DOF 20: 0.15\n","Pearson correlation for DOF 21: 0.84\n","RMSE for DOF 21: 0.08\n","Pearson correlation for DOF 22: 0.9\n","RMSE for DOF 22: 0.19\n","Test labels for fold 10: [11. 15. 17.  9.]\n","Training input shape: (8241, 96), Training target shape: (8241, 22)\n","Testing input shape: (728, 96), Testing target shape: (728, 22)\n","LSTM training input shape: (8227, 15, 96), LSTM training output shape: (8227, 22)\n","LSTM testing input shape: (714, 15, 96), LSTM testing output shape: (714, 22)\n","Epoch 1/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 1.7705e-04 - val_loss: 0.0146 - learning_rate: 0.0010\n","Epoch 2/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.0351e-04 - val_loss: 0.0194 - learning_rate: 0.0010\n","Epoch 3/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.6027e-04 - val_loss: 0.0175 - learning_rate: 0.0010\n","Epoch 4/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 2.4586e-04 - val_loss: 0.0213 - learning_rate: 0.0010\n","Epoch 5/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.8496e-04 - val_loss: 0.0159 - learning_rate: 5.0000e-04\n","Epoch 6/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.4497e-04 - val_loss: 0.0162 - learning_rate: 5.0000e-04\n","Epoch 7/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.3309e-04 - val_loss: 0.0159 - learning_rate: 5.0000e-04\n","Epoch 8/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.1540e-04 - val_loss: 0.0158 - learning_rate: 2.5000e-04\n","Epoch 9/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0730e-04 - val_loss: 0.0169 - learning_rate: 2.5000e-04\n","Epoch 10/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0994e-04 - val_loss: 0.0165 - learning_rate: 2.5000e-04\n","Epoch 11/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0192e-04 - val_loss: 0.0158 - learning_rate: 1.2500e-04\n","Epoch 12/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 1.0190e-04 - val_loss: 0.0158 - learning_rate: 1.2500e-04\n","Epoch 13/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.5227e-05 - val_loss: 0.0167 - learning_rate: 1.2500e-04\n","Epoch 14/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.4121e-05 - val_loss: 0.0165 - learning_rate: 6.2500e-05\n","Epoch 15/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.2929e-05 - val_loss: 0.0167 - learning_rate: 6.2500e-05\n","Epoch 16/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3889e-05 - val_loss: 0.0166 - learning_rate: 6.2500e-05\n","Epoch 17/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1812e-05 - val_loss: 0.0164 - learning_rate: 3.1250e-05\n","Epoch 18/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8748e-05 - val_loss: 0.0165 - learning_rate: 3.1250e-05\n","Epoch 19/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0657e-05 - val_loss: 0.0163 - learning_rate: 3.1250e-05\n","Epoch 20/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0322e-05 - val_loss: 0.0165 - learning_rate: 1.5625e-05\n","Epoch 21/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9338e-05 - val_loss: 0.0164 - learning_rate: 1.5625e-05\n","Epoch 22/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9571e-05 - val_loss: 0.0165 - learning_rate: 1.5625e-05\n","Epoch 23/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.1445e-05 - val_loss: 0.0165 - learning_rate: 7.8125e-06\n","Epoch 24/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7730e-05 - val_loss: 0.0165 - learning_rate: 7.8125e-06\n","Epoch 25/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0230e-05 - val_loss: 0.0164 - learning_rate: 7.8125e-06\n","Epoch 26/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8987e-05 - val_loss: 0.0164 - learning_rate: 3.9063e-06\n","Epoch 27/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7357e-05 - val_loss: 0.0164 - learning_rate: 3.9063e-06\n","Epoch 28/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 8.7614e-05 - val_loss: 0.0165 - learning_rate: 3.9063e-06\n","Epoch 29/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6913e-05 - val_loss: 0.0165 - learning_rate: 1.9531e-06\n","Epoch 30/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8778e-05 - val_loss: 0.0165 - learning_rate: 1.9531e-06\n","Epoch 31/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6141e-05 - val_loss: 0.0165 - learning_rate: 1.9531e-06\n","Epoch 32/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8785e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 33/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.3069e-05 - val_loss: 0.0166 - learning_rate: 1.0000e-06\n","Epoch 34/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6226e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 35/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7418e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 36/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6741e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 37/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8932e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 38/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6981e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 39/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7327e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 40/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 8.7035e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 41/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.5812e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 42/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7225e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 43/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 8.9772e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 44/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9171e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 45/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8671e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 46/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7032e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 47/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8859e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 48/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7100e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 49/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8563e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 50/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7832e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 51/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6463e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 52/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8782e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 53/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7446e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 54/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7478e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 55/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0589e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 56/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0041e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 57/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8517e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 58/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8813e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 59/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8108e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 60/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8313e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 61/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 9.0599e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 62/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9368e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 63/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8151e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 64/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6260e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 65/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7937e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 66/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7325e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 67/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7982e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 68/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8730e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 69/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.5574e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 70/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7251e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 71/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8638e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 72/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.9826e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 73/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8521e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 74/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8229e-05 - val_loss: 0.0164 - learning_rate: 1.0000e-06\n","Epoch 75/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8667e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 76/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8509e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 77/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7021e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 78/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.8089e-05 - val_loss: 0.0166 - learning_rate: 1.0000e-06\n","Epoch 79/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7680e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 80/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.6262e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","Epoch 81/200\n","\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 8.7648e-05 - val_loss: 0.0165 - learning_rate: 1.0000e-06\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n","Predicted output shape: (714, 22)\n","Actual test output shape: (714, 22)\n","Pearson correlation for DOF 1: 0.8\n","RMSE for DOF 1: 0.09\n","Pearson correlation for DOF 2: 0.52\n","RMSE for DOF 2: 0.14\n","Pearson correlation for DOF 3: 0.53\n","RMSE for DOF 3: 0.22\n","Pearson correlation for DOF 4: 0.64\n","RMSE for DOF 4: 0.15\n","Pearson correlation for DOF 5: 0.77\n","RMSE for DOF 5: 0.15\n","Pearson correlation for DOF 6: 0.77\n","RMSE for DOF 6: 0.22\n","Pearson correlation for DOF 7: 0.5\n","RMSE for DOF 7: 0.15\n","Pearson correlation for DOF 8: 0.73\n","RMSE for DOF 8: 0.14\n","Pearson correlation for DOF 9: 0.79\n","RMSE for DOF 9: 0.22\n","Pearson correlation for DOF 10: 0.68\n","RMSE for DOF 10: 0.2\n","Pearson correlation for DOF 11: 0.82\n","RMSE for DOF 11: 0.07\n","Pearson correlation for DOF 12: 0.75\n","RMSE for DOF 12: 0.12\n","Pearson correlation for DOF 13: 0.85\n","RMSE for DOF 13: 0.2\n","Pearson correlation for DOF 14: 0.79\n","RMSE for DOF 14: 0.1\n","Pearson correlation for DOF 15: 0.82\n","RMSE for DOF 15: 0.08\n","Pearson correlation for DOF 16: 0.74\n","RMSE for DOF 16: 0.1\n","Pearson correlation for DOF 17: 0.87\n","RMSE for DOF 17: 0.2\n","Pearson correlation for DOF 18: 0.86\n","RMSE for DOF 18: 0.1\n","Pearson correlation for DOF 19: 0.92\n","RMSE for DOF 19: 0.09\n","Pearson correlation for DOF 20: 0.67\n","RMSE for DOF 20: 0.16\n","Pearson correlation for DOF 21: -0.44\n","RMSE for DOF 21: 0.28\n","Pearson correlation for DOF 22: 0.82\n","RMSE for DOF 22: 0.2\n"]}],"source":["import numpy as np\n","import math\n","from sklearn.metrics import mean_squared_error\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","sequence_length = 15  # Define sequence length for LSTM input\n","n_features = 96  # Number of input features\n","\n","# Initialize storage for Pearson correlation and MSE for each fold\n","pearson = {}\n","mse = {}\n","for i in range(1, 23):\n","    pearson[i] = []\n","    mse[i] = []\n","\n","# Labels range from 1 to 17 (excluding 0)\n","labels = list(range(1, 18)) #for E1\n","# labels = list(range(18, 41)) #for E2 23 movements\n","\n","\n","\n","# Check unique labels in Data1 and their counts (assuming the label is in the last column)\n","unique_labels, counts = np.unique(Data1[:, -1], return_counts=True)\n","available_labels = dict(zip(unique_labels, counts))\n","\n","# Print available labels and counts for debugging\n","print(\"Available labels and their counts:\", available_labels)\n","\n","# Filter out labels that have data\n","valid_labels = [label for label, count in available_labels.items() if count \u003e 0 and label != 0]\n","\n","if not valid_labels:\n","    raise ValueError(\"No valid labels found in dataset.\")\n","\n","# Loop over 10-fold cross-validation\n","for i in range(1, 11):\n","    # Randomly select 3 different labels for testing\n","    test_labels = np.random.choice(valid_labels, 4, replace=False)\n","    print(f\"Test labels for fold {i}: {test_labels}\")\n","\n","    # Split the data into training and testing based on the 3 selected labels\n","    D_test = Data1[np.isin(Data1[:, -1], test_labels)]  # Test data for the selected labels\n","    D_train = Data1[~np.isin(Data1[:, -1], test_labels)]  # Training data for the remaining labels\n","\n","    # Extract features and targets for training and testing\n","    # X_train = D_train[:, 36:58]  # Target for training\n","    # Z_train = D_train[:, 58:82]  # Input features for training\n","    # X_test = D_test[:, 36:58]  # Target for testing\n","    # Z_test = D_test[:, 58:82]  # Input features for testing\n","\n","    # X_train = D_train[:, 60:82]  # Target for training\n","    # Z_train = D_train[:, 0:60]  # Input features for training\n","\n","    # X_test = D_test[:, 60:82]  # Target for testing\n","    # Z_test = D_test[:, 0:60 ]  # Input features for testing\n","\n","    X_train = D_train[:, 96:118]  # Target for training\n","    Z_train = D_train[:, 0:96]  # Input features for training\n","\n","    X_test = D_test[:, 96:118]  # Target for testing\n","    Z_test = D_test[:, 0:96 ]  # Input features for testing\n","\n","    print(f\"Training input shape: {Z_train.shape}, Training target shape: {X_train.shape}\")\n","    print(f\"Testing input shape: {Z_test.shape}, Testing target shape: {X_test.shape}\")\n","\n","    # Prepare input and output for LSTM (training)\n","    n_sequences_train = len(Z_train) - sequence_length + 1\n","    in_train = np.zeros((n_sequences_train, sequence_length, n_features))\n","    out_train = np.zeros((n_sequences_train, X_train.shape[1]))  # Output shape should match target\n","\n","    for j in range(n_sequences_train):\n","        in_train[j] = Z_train[j:j + sequence_length]\n","        out_train[j] = X_train[j + sequence_length - 1]  # Target is the last step in the sequence\n","\n","    # Prepare input and output for LSTM (testing)\n","    n_sequences_test = len(Z_test) - sequence_length + 1\n","    in_test = np.zeros((n_sequences_test, sequence_length, n_features))\n","    out_test = np.zeros((n_sequences_test, X_test.shape[1]))\n","\n","    for j in range(n_sequences_test):\n","        in_test[j] = Z_test[j:j + sequence_length]\n","        out_test[j] = X_test[j + sequence_length - 1]  # Target is the last step in the sequence\n","\n","    # Print the shape of the prepared data for sanity check\n","    print(f\"LSTM training input shape: {in_train.shape}, LSTM training output shape: {out_train.shape}\")\n","    print(f\"LSTM testing input shape: {in_test.shape}, LSTM testing output shape: {out_test.shape}\")\n","\n","    ######### Model Training ##########\n","    # Compile the model with Adam optimizer and Mean Squared Error loss\n","    optimizer = Adam(learning_rate=0.001)  # Initial learning rate\n","    model.compile(optimizer=optimizer, loss='mean_squared_error')\n","\n","    # ReduceLROnPlateau callback to dynamically reduce the learning rate if the model stops improving\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","\n","    # Early stopping to prevent overfitting\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=80)\n","\n","    # Train the model\n","    history = model.fit(in_train, out_train, validation_split=0.2, batch_size=32, epochs=200, verbose=1, callbacks=[early_stopping, reduce_lr])\n","\n","    # Model testing\n","    output_predicted = model.predict(in_test)\n","\n","    # Handle sequence length discrepancy if any\n","    n = len(out_test) - len(output_predicted)\n","    if n == 0:\n","        out_test_final = out_test\n","    else:\n","        out_test_final = out_test[:-n, :]\n","\n","    # Print shapes for sanity check\n","    print(f\"Predicted output shape: {output_predicted.shape}\")\n","    print(f\"Actual test output shape: {out_test_final.shape}\")\n","\n","    # Calculate Pearson correlation and RMSE for each dimension (1 to 22)\n","    for k in range(1, 23):\n","      # Calculate Pearson correlation coefficient\n","      cc_value = np.corrcoef(out_test_final[:, k - 1], output_predicted[:, k - 1])[0, 1]\n","    # Calculate RMSE\n","      rmse_value = math.sqrt(mean_squared_error(out_test_final[:, k - 1], output_predicted[:, k - 1]))\n","    # Store values rounded to two decimal places\n","      pearson[k].append(round(cc_value, 2))  # Round CC value\n","      mse[k].append(round(rmse_value, 2))    # Round RMSE value\n","     # Print the rounded values\n","      print(f\"Pearson correlation for DOF {k}: {pearson[k][-1]}\")  # Accessing the last added value\n","      print(f\"RMSE for DOF {k}: {mse[k][-1]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iAE5nciGtQQx"},"outputs":[{"name":"stdout","output_type":"stream","text":["CC:[np.float64(0.6), np.float64(0.42), np.float64(0.62), np.float64(0.83), np.float64(0.93), np.float64(0.82), np.float64(0.96), np.float64(0.95), np.float64(0.97), np.float64(0.8)]\n","CC:[np.float64(0.13), np.float64(0.37), np.float64(0.6), np.float64(0.87), np.float64(0.86), np.float64(0.86), np.float64(0.62), np.float64(0.94), np.float64(0.67), np.float64(0.52)]\n","CC:[np.float64(-0.01), np.float64(0.29), np.float64(0.8), np.float64(0.92), np.float64(0.67), np.float64(0.59), np.float64(0.66), np.float64(0.95), np.float64(0.53), np.float64(0.53)]\n","CC:[np.float64(0.38), np.float64(0.51), np.float64(0.54), np.float64(0.83), np.float64(0.92), np.float64(0.79), np.float64(0.92), np.float64(0.94), np.float64(0.92), np.float64(0.64)]\n","CC:[np.float64(0.79), np.float64(0.72), np.float64(0.69), np.float64(0.88), np.float64(0.91), np.float64(0.97), np.float64(0.71), np.float64(0.96), np.float64(0.82), np.float64(0.77)]\n","CC:[np.float64(0.71), np.float64(0.8), np.float64(0.52), np.float64(0.84), np.float64(0.97), np.float64(0.98), np.float64(0.88), np.float64(0.94), np.float64(0.74), np.float64(0.77)]\n","CC:[np.float64(0.44), np.float64(0.71), np.float64(0.65), np.float64(0.86), np.float64(0.93), np.float64(0.86), np.float64(0.74), np.float64(0.93), np.float64(0.82), np.float64(0.5)]\n","CC:[np.float64(0.74), np.float64(0.72), np.float64(0.67), np.float64(0.88), np.float64(0.9), np.float64(0.96), np.float64(0.7), np.float64(0.95), np.float64(0.88), np.float64(0.73)]\n","CC:[np.float64(0.74), np.float64(0.82), np.float64(0.54), np.float64(0.9), np.float64(0.96), np.float64(0.98), np.float64(0.93), np.float64(0.96), np.float64(0.97), np.float64(0.79)]\n","CC:[np.float64(0.68), np.float64(0.79), np.float64(0.56), np.float64(0.86), np.float64(0.94), np.float64(0.96), np.float64(0.89), np.float64(0.97), np.float64(0.94), np.float64(0.68)]\n","CC:[np.float64(0.54), np.float64(0.79), np.float64(0.6), np.float64(0.94), np.float64(0.94), np.float64(0.9), np.float64(0.96), np.float64(0.97), np.float64(0.94), np.float64(0.82)]\n","CC:[np.float64(0.78), np.float64(0.82), np.float64(0.75), np.float64(0.92), np.float64(0.92), np.float64(0.96), np.float64(0.84), np.float64(0.97), np.float64(0.9), np.float64(0.75)]\n","CC:[np.float64(0.89), np.float64(0.92), np.float64(0.64), np.float64(0.98), np.float64(0.96), np.float64(0.98), np.float64(0.98), np.float64(0.98), np.float64(0.97), np.float64(0.85)]\n","CC:[np.float64(0.41), np.float64(0.52), np.float64(0.78), np.float64(0.58), np.float64(0.92), np.float64(0.85), np.float64(0.94), np.float64(0.91), np.float64(0.81), np.float64(0.79)]\n","CC:[np.float64(0.59), np.float64(0.84), np.float64(0.52), np.float64(0.94), np.float64(0.78), np.float64(0.97), np.float64(0.96), np.float64(0.96), np.float64(0.94), np.float64(0.82)]\n","CC:[np.float64(0.72), np.float64(0.85), np.float64(0.75), np.float64(0.94), np.float64(0.94), np.float64(0.98), np.float64(0.9), np.float64(0.97), np.float64(0.91), np.float64(0.74)]\n","CC:[np.float64(0.89), np.float64(0.92), np.float64(0.69), np.float64(0.98), np.float64(0.95), np.float64(0.99), np.float64(0.98), np.float64(0.98), np.float64(0.97), np.float64(0.87)]\n","CC:[np.float64(0.79), np.float64(0.66), np.float64(0.79), np.float64(0.78), np.float64(0.97), np.float64(0.98), np.float64(0.95), np.float64(0.96), np.float64(0.97), np.float64(0.86)]\n","CC:[np.float64(0.22), np.float64(0.46), np.float64(0.82), np.float64(0.91), np.float64(0.94), np.float64(0.89), np.float64(0.93), np.float64(0.95), np.float64(0.94), np.float64(0.92)]\n","CC:[np.float64(0.4), np.float64(0.77), np.float64(0.58), np.float64(0.91), np.float64(0.84), np.float64(0.85), np.float64(0.78), np.float64(0.8), np.float64(0.71), np.float64(0.67)]\n","CC:[np.float64(0.69), np.float64(0.88), np.float64(-0.21), np.float64(0.93), np.float64(0.86), np.float64(0.9), np.float64(0.84), np.float64(0.95), np.float64(0.84), np.float64(-0.44)]\n","CC:[np.float64(0.19), np.float64(0.43), np.float64(0.64), np.float64(0.82), np.float64(0.88), np.float64(0.78), np.float64(0.68), np.float64(0.91), np.float64(0.9), np.float64(0.82)]\n"]}],"source":["for i in range (1,23):\n"," # Getting cc and rmse\n","  print(f\"CC:{pearson[i]}\")\n"," # print(\"RMSE: %s\" % mse[i])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Vm1g1p0vkBHz"},"outputs":[{"name":"stdout","output_type":"stream","text":["CC: [[1.         0.51710418]\n"," [0.51710418 1.        ]]\n"]}],"source":["  print(\"CC: %s\" %np.corrcoef(out_test[:,1],output_predicted[:,1]))\n"]},{"cell_type":"markdown","metadata":{"id":"RXXIJC68ilUA"},"source":["### **Get the mean and std of CC and RMSE**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8mGtSaCCilIM"},"outputs":[{"name":"stdout","output_type":"stream","text":["CC Mean 1: 0.7899999999999999\n","CC STD 1: 0.176351920885484\n","----------------------------------------\n","CC Mean 2: 0.6439999999999999\n","CC STD 2: 0.24286621831782204\n","----------------------------------------\n","CC Mean 3: 0.5930000000000001\n","CC STD 3: 0.27404561664073374\n","----------------------------------------\n","CC Mean 4: 0.739\n","CC STD 4: 0.19501025614054254\n","----------------------------------------\n","CC Mean 5: 0.8220000000000001\n","CC STD 5: 0.09806120537705011\n","----------------------------------------\n","CC Mean 6: 0.8150000000000001\n","CC STD 6: 0.133285408053545\n","----------------------------------------\n","CC Mean 7: 0.744\n","CC STD 7: 0.16243152403397562\n","----------------------------------------\n","CC Mean 8: 0.813\n","CC STD 8: 0.1053612832116238\n","----------------------------------------\n","CC Mean 9: 0.859\n","CC STD 9: 0.1327742444904131\n","----------------------------------------\n","CC Mean 10: 0.827\n","CC STD 10: 0.13587126259809315\n","----------------------------------------\n","CC Mean 11: 0.8400000000000001\n","CC STD 11: 0.14676511847165863\n","----------------------------------------\n","CC Mean 12: 0.861\n","CC STD 12: 0.07968061244744547\n","----------------------------------------\n","CC Mean 13: 0.915\n","CC STD 13: 0.10121758740456126\n","----------------------------------------\n","CC Mean 14: 0.7510000000000001\n","CC STD 14: 0.17438176510174452\n","----------------------------------------\n","CC Mean 15: 0.8320000000000001\n","CC STD 15: 0.15295751043999115\n","----------------------------------------\n","CC Mean 16: 0.8699999999999999\n","CC STD 16: 0.09412757300600075\n","----------------------------------------\n","CC Mean 17: 0.9219999999999999\n","CC STD 17: 0.08681013765684283\n","----------------------------------------\n","CC Mean 18: 0.8710000000000001\n","CC STD 18: 0.1056834897228512\n","----------------------------------------\n","CC Mean 19: 0.798\n","CC STD 19: 0.237815054191277\n","----------------------------------------\n","CC Mean 20: 0.731\n","CC STD 20: 0.14257980221616245\n","----------------------------------------\n","CC Mean 21: 0.6239999999999999\n","CC STD 21: 0.48193775531701183\n","----------------------------------------\n","CC Mean 22: 0.7050000000000001\n","CC STD 22: 0.22100904958847276\n","----------------------------------------\n","RMSE Mean 1: 0.11100000000000003\n","RMSE STD 1: 0.056999999999999995\n","----------------------------------------\n","RMSE Mean 2: 0.13400000000000004\n","RMSE STD 2: 0.04800000000000001\n","----------------------------------------\n","RMSE Mean 3: 0.16899999999999998\n","RMSE STD 3: 0.0587281874401041\n","----------------------------------------\n","RMSE Mean 4: 0.135\n","RMSE STD 4: 0.04716990566028302\n","----------------------------------------\n","RMSE Mean 5: 0.121\n","RMSE STD 5: 0.023853720883753125\n","----------------------------------------\n","RMSE Mean 6: 0.13999999999999999\n","RMSE STD 6: 0.06855654600401044\n","----------------------------------------\n","RMSE Mean 7: 0.096\n","RMSE STD 7: 0.02615339366124404\n","----------------------------------------\n","RMSE Mean 8: 0.119\n","RMSE STD 8: 0.023\n","----------------------------------------\n","RMSE Mean 9: 0.13499999999999998\n","RMSE STD 9: 0.07074602462329596\n","----------------------------------------\n","RMSE Mean 10: 0.128\n","RMSE STD 10: 0.05546169849544819\n","----------------------------------------\n","RMSE Mean 11: 0.084\n","RMSE STD 11: 0.0332264954516723\n","----------------------------------------\n","RMSE Mean 12: 0.098\n","RMSE STD 12: 0.025219040425836985\n","----------------------------------------\n","RMSE Mean 13: 0.11700000000000002\n","RMSE STD 13: 0.06603786792439624\n","----------------------------------------\n","RMSE Mean 14: 0.088\n","RMSE STD 14: 0.04069397989875161\n","----------------------------------------\n","RMSE Mean 15: 0.09\n","RMSE STD 15: 0.0447213595499958\n","----------------------------------------\n","RMSE Mean 16: 0.096\n","RMSE STD 16: 0.03382306905057553\n","----------------------------------------\n","RMSE Mean 17: 0.122\n","RMSE STD 17: 0.06997142273814361\n","----------------------------------------\n","RMSE Mean 18: 0.079\n","RMSE STD 18: 0.02467792535850613\n","----------------------------------------\n","RMSE Mean 19: 0.12300000000000003\n","RMSE STD 19: 0.07197916365171243\n","----------------------------------------\n","RMSE Mean 20: 0.13399999999999998\n","RMSE STD 20: 0.02835489375751565\n","----------------------------------------\n","RMSE Mean 21: 0.11600000000000002\n","RMSE STD 21: 0.0785111457055621\n","----------------------------------------\n","RMSE Mean 22: 0.11499999999999999\n","RMSE STD 22: 0.07351870510285122\n","----------------------------------------\n"]}],"source":["cc=[]\n","cstd=[]\n","rms=[]\n","rmsstd=[]\n","for i in range(1, 23):\n","  print(\"CC Mean %s: %s\" % (i , np.mean(pearson[i])))\n","  print(\"CC STD %s: %s\" % (i , np.std(pearson[i])))\n","  print(\"----------------------------------------\")\n","  cc.append(np.mean(pearson[i]))\n","  cstd.append(np.std(pearson[i]))\n","\n","for i in range (1,23):\n","  print(\"RMSE Mean %s: %s\"  %(i, np.mean(mse[i])))\n","  print(\"RMSE STD %s: %s\"  %(i, np.std(mse[i])))\n","  print(\"----------------------------------------\")\n","  rms.append(np.mean(mse[i]))\n","  rmsstd.append(np.std(mse[i]))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4QMQ00NgsUxw"},"outputs":[],"source":["#Save data in excel file\n","\n","import openpyxl\n","\n","# Load the existing workbook\n","from google.colab import drive\n","workbook_path = '/content/drive/My Drive/Colab Notebooks/dataset/Ninapro CNN-LSTM Subjectdependant_8features_E1.xlsx'\n","\n","wb = openpyxl.load_workbook(workbook_path)\n","\n","\n","# Select the active sheet\n","sheet = wb.active\n","\n","row_name = 'S40'  # Change this to the appropriate row name for each run\n","\n","# Find the row with the specified row name\n","for row in sheet.iter_rows(min_row=1, max_row=sheet.max_row):\n","    if row[0].value == row_name:\n","        target_row = row[0].row\n","        break\n","\n","# Write the data to the found row, starting from the second column\n","for col, value in enumerate(cc, start=2):  # start=2 to skip the first column for the label\n","    sheet.cell(row=target_row, column=col, value=value)\n","\n","# Save the workbook\n","wb.save(workbook_path)\n"]},{"cell_type":"markdown","metadata":{"id":"PCr6zUnNCS1y"},"source":["### **plot predicted vs actual**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1Z05SmgbJm4n0ILVA_ZkV0-MNVO8yjZW3"},"id":"iS_6R_XkCSpa","outputId":"a4c648e4-3c1f-4335-bab4-b41a9b12a9dc"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","for i in range (0,22):\n","  n_rows = out_test.shape[0]\n","  x = np.arange(n_rows)\n","\n","  y1 = out_test[:, i]  # Column\n","  y2 = output_predicted[:, i]\n","\n","  plt.figure(figsize=(12, 6))\n","\n","  # Plotting each column\n","  plt.plot(x, y1, label='Actual', color='blue')  # Line for column 1\n","  plt.plot(x, y2, label='Predicted', color='red')  # Line for column 2\n","  # Calculate the mean and current correlation coefficient separately\n","  cc_mean = np.mean(pearson[i+1])\n","  cc_current = np.corrcoef(out_test[:, i], output_predicted[:, i])[0, 1]\n","  # Combine them into the plot title\n","  plot_title = \"CC Mean: {:.2f}, CC Current: {:.2f}\".format(cc_mean, cc_current)\n","\n","  plt.title(plot_title)\n","  plt.xlabel('Index')\n","  plt.ylabel('Values')\n","  plt.legend()\n","\n","  plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNKfoo/DOz1gomM/lYgW8Bd","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}